# Source code

The source code in this here is arranged in a loose chronological order, reflecting the sequence in which it is called in the scripts presented throughout this book.

## AUC_rad script: 'AUC_fun' function

```{r AUC_rad: AUC_fun, eval = F, echo = T}
# returns the AUC of the actual data.
AUC_fun <- function(df) {
  
  # defining variables to work with
  d <- df
  
  lines <- character()
  # for loop, checks if CF$cline is in vector lines, if so, do nothing, else append to vector. 
  for (line in d$cline) (
    ifelse(line %in% lines, NA, lines <- c(lines, line)))
  
  # separate into dataframes according to cline
  per_line <- split(d, f = d$cline, drop = TRUE)
  
  # define dose_vetor
  dose_vector <- unique(d$dose)
  
  
  # computes AUC for given predicted survival and dose given by dose_vector
  AUC_calc <- function(df) {
    # extract actual data
    rel_mean <- df$relative_mean
    
    # extracts number of experiemnts 
    n <- length(unique(d$Exp))
    #remove 2th and 3th number (are duplicates)
    rel_mean <- rel_mean[seq(1, length(rel_mean), n)]
    
    # compute maximal 
    max_AUC <- max(dose_vector)*1
    
    #compute AUC
    act_AUC <- AUC(x=dose_vector, y = rel_mean)
    
    # make dataframe
    datafr <- data.frame(max_AUC = max_AUC,
                         act_AUC = act_AUC, 
                         rel_AUC = act_AUC/max_AUC,
                         expcode = unique(df$expcode),
                         cline= unique(df$cline),
                         treatment = unique(df$treatment ) )
    
    
    return(datafr)
  }
  
  # Store in vector
  AUC_vector <- lapply(per_line, AUC_calc) 
  
  #merge dataframes
  df = do.call(rbind, AUC_vector)
  
  return(df) 
  
}

```

## fitter_rad script: 'fitter' function
```{r fitter_rad: fitter, eval = F,echo = T}
fitter <- function(df) {
  
  # defining variables to work with
  d <- df
  
  
  lines <- character()
  # for loop, checks if CF$cline is in vector lines, if so, do nothing, else append to vector. 
  for (line in d$cline) (
    ifelse(line %in% lines, NA, lines <- c(lines, line)))
  
  # separate into dataframes according to cline
  per_line <- split(d, f = d$cline, drop = TRUE)
  
  
  # Function to make model for every line and dataframe with predicted data for each line. 
  fit_model= function(line) {
    # line is a dataframe. Outputs the fits of norm and dose
    fit <- drm(relative ~ dose, # define y -axis (ncolonies) and x-axis (dose)
               data = line, # defines dataframe
               fct = LL.4 (names = c('Slope', "Lower Limit", "Upper Limit", "IC50"))) # defines to fit a log-losistic model)
    
    newdata <- expand.grid(dose=exp(seq(log(0.00000001), log(max(df$dose) + 1000), length=1000))) # new data with doses. Note: lowest dose is not
    # log 0 but log('very small number') because otherwise this will hamper the scaling in ggplot later on. 
    pm <- predict(fit, newdata=newdata, interval="confidence") # new data with predictions and confidence intervals
    newdata$pred <- pm[,1] # add prediction values to new data.
    newdata$predmin <- pm[,2] # add lower bounderies to new data 
    newdata$predmax <- pm[,3] # add upper bounderies to new data 
    newdata$cline <- line$cline[1] # add column with cline.
    newdata$expcode = unique(df$expcode)
    return(newdata)
  }
  
  # Store in vector
  data_frames <- lapply(per_line, fit_model) 
  
  
  #merge dataframes
  df = do.call(rbind, data_frames)
  
  return(df) 
  
}
```

## ic50_rad script: 'IC50_fun' function
```{r ic50_rad: IC50_fun, eval = F,echo = T}
IC50_fun <- function(df, rad) {
  
  # defining variables to work with
  ifelse(is.null(rad), d<-df, d <- subset(df, rec_rad == rad))
  
  lines <- character()
  # for loop, checks if CF$cline is in vector lines, if so, do nothing, else append to vector. 
  for (line in d$cline) (
    ifelse(line %in% lines, NA, lines <- c(lines, line)))
  
  # separate into dataframes according to cline
  per_line <- split(d, f = d$cline, drop =TRUE)
  
  
  # Function to make model for every line and dataframe with predicted data for each line. 
  ic50= function(line) {
    # line is a dataframe. Outputs the fits of norm and dose
    fit <- drm(relative ~ dose, # define y -axis (ncolonies) and x-axis (dose)
               data = line, # defines dataframe
               fct = LL.4 (names = c('Slope', "Lower Limit", "Upper Limit", "IC50"))) # defines to fit a log-losistic model)
    
    return(coef(fit)[4])
  }
  
  # Store in vector
  IC50_vector <- lapply(per_line, ic50) 
  
  #merge dataframes
  df = do.call(rbind, IC50_vector)
  
  return(df) 
  
} 
```

## relativize_dr script: 'relative' function

```{r relativize_dr: relative, eval = F,echo = T}
relative <- function(df, rad) {
  #' @param df with dose response data and columns cline, dose, Exp, 
  #' rec_rad, expcode, ncolonies
  #' @param rad if line received radiation (T or F), stored in column rec_rad
  #' @return relativized data where dose = 0 is used as 100%
  
  # defining variables to work with
  ifelse(rad == T, d<-subset(df, rec_rad == 1), d<-subset(df, rec_rad == 0) )
  
  # define ncolonies
  column <- "ncolonies"
  
  # Extracts the column name.
  col <- d[c(column)]
  
  # extracts number of experiemnts 
  n <- length(unique(d$Exp))
  
  # Takes mean every nth row
  
  mean_fun <- function(x) {
    m <- mean(x, na.rm = TRUE)
    return(m)
  }
  
  mean <- aggregate(col,list(rep(1:(nrow(col)%/%n+1),each=n,len=nrow(col))), mean_fun)[-1]
  # Duplicates (n=2) or triplicates (n=3) the rows.
  mean <- mean[rep(seq_len(nrow(mean)), each = n), ]
  # Adds everything to the dataframe. 
  d["mean"] <- mean
  
  # Select mean values of 0 concentration
  d <- d %>%
    group_by(cline) %>%
    arrange(cline,dose)
  
  first <- d[d$dose==0, ] %>%
    dplyr::select(cline, value100=mean)
  
  # Make cline a factor
  d$cline<-factor(d$cline)
  
  # Merge first original (d)
  d <- d %>%
    merge(first,by=c("cline"))
  
  # Extract only every nth row.
  d = d[seq(1, nrow(d), n), ]
  
  # make new column with relative, called relative
  d$relative = d$ncolonies/d$value100
  d$relative_mean = d$mean/d$value100
  
  d<-subset(d, select=-c(mean,value100))
  
  # compute relative standard error of the mean
  # define the column with sem in it
  column <- "relative"
  
  # Extracts the column name.
  col <- d[c(column)]
  
  
  sem_fun <- function(x) {
    std <- sd(x, na.rm = TRUE)
    vector <- na.omit(x)
    
    sem <- std/sqrt(length(vector))
    return(sem)
  }
  
  sem <- aggregate(col,list(rep(1:(nrow(col)%/%n+1),each=n,len=nrow(col))),sem_fun)[-1]
  sem <- sem[rep(seq_len(nrow(sem)), each = n), ]
  d["relative_sem"] <- sem
  
  return(d)
  
}
```

## quality_functions script: 'quality_check', 'quality_select' and 'check_quality' functions
```{r quality_functions, eval = F,echo = T}
quality_check <- function(inputdir, model) {
  #' @param inputdir is directory containing the standard aneufinder output for each plate
  #' model is which model to use for the quality check: either dnacopy, edivisive or HMM
  #' quality_check will make quality metrics for each plate
  #' quality_check assumes that rdaBaseDirectory contains folder with models for each plate
  #' each plate folder has to contain a MODEL folder and a method-'dnacopy, edivisive, or HMM' folder
  #' @example quality_check(inputdir = rdaBaseDirectory, model = 'edivisive')
  
  # go to folder with appropiate files
  rda_folder <- paste0(inputdir, '/MODELS', '/method-', model)
  
  # extract files
  rda_files <- list.files(rda_folder, full.names = TRUE)
  
  # run quality check on each file
  cl <-
    clusterByQuality(
      rda_files,
      measures = c(
        'spikiness',
        'num.segments',
        'entropy',
        'bhattacharyya',
        'sos'
      )
    )
  
  return(cl)
  
}

quality_select <- function(cl, spik, bhat) {
  #' selects all files that meets the defined quality requirements
  #' @param cl output of the clusterByQuality function in AneuFinder
  #' @param spik the spikiness treshhold. All clusters with spikiness above
  #' the treshold will be removed
  #' @param bhat the bhattacharrya score. All clusters with bhattacharrya below
  #' the treshold will be removed
  #' @return returns a vector of selected files paths
  
  # convert to df to allow easy wrangling
  cl_df <- as.data.frame(cl$parameters)
  
  # remove higher than spik
  spik <- subset(cl_df, spikiness < spik)
  
  # remove lower than bhat
  spik_bhat <- subset(spik,  bhattacharyya > bhat)
  
  cluster_n <- nrow(spik_bhat)
  
  # create vector of selected files
  selected.files <- unlist(cl$classification[0:cluster_n])
  
  return(selected.files)
  
}

check_quality <- function(cl) {
  return(cl$parameters)
}
  
}
```

## plot_pca_kmeans script: 'draw_pca', 'k_cluster', 'draw_pca_double' and 'k_cluster_double' functions
```{r plot_pca_kmeans, eval = F,echo = T}
draw_pca <-
  function(list_files1,
           list_files2,
           size,
           legend_position,
           baseline_kra,
           recurrence_kra,
           ssdna004 = F) {
    cells <- c(list_files1, list_files2)
    
    df <- plot_pca(
      cells,
      colorBy = classes,
      PC1 = 1,
      PC2 = 2,
      plot = F
    )
    
    df$class <- str_extract(rownames(df),  'KRA-0\\d+')
    num <- str_extract(rownames(df),  '_\\d+\\.')
    num <- str_remove_all(num, pattern = '\\.')
    df$label <- paste0(df$class, num)
    pc1 <- colnames(df)[1]
    pc2 <- colnames(df)[2]
    
    colnames(df) <- c('PC1', 'PC2', 'class', 'label')
    
    col_vals <- ifelse(ssdna004 == T, list(c("#D69C4E", "#999999")), list(c("#999999", "#D69C4E")))
    label_vals <- ifelse(ssdna004 == T, list(c('Recurrence', 'Baseline')), list(c('Baseline', 'Recurrence')))
    
    p <- ggplot(data = df, aes(label = label)) +
      geom_point(size = size, aes(x = PC1,
                                  y = PC2,
                                  col = class)) +
      # scale_color_manual(values = c("#FFDB6D", "#00AFBB")) +
      scale_color_manual(
        name = '',
        values = col_vals[[1]],
        labels = label_vals[[1]]
      ) +
      
      # or consider '#9e1303' for second cycle of recurrence
      
      theme_cowplot() +
      theme(legend.position = legend_position,
            text = element_text(size = 17),
            axis.text = element_text(size = 15)) +
      
      labs(x = pc1, y = pc2)
    p
    
  
    
    # ggplotly(p)
    
  }


k_cluster <- function(list_files1,
                      list_files2,
                      cluster_n,
                      cols,
                      labels,
                      legend_position,
                      normalize,
                      return_elbow = F) {
  
  require(factoextra)
  
  cells <- c(list_files1, list_files2)
  
  df12 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 1,
    PC2 = 2,
    plot = F
  )

  
  df34 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 3,
    PC2 = 4,
    plot = F
  )
  
  df56 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 5,
    PC2 = 6,
    plot = F
  )
  
  df78 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 7,
    PC2 = 8,
    plot = F
  )
  
  df910 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 9,
    PC2 = 10,
    plot = F
  )
  
  
  df <- cbind(df12, df34, df56, df78, df910)
  
  
  if (normalize) {
    # extract variance explained for each pca
    pca_var <-
      as.numeric(str_match(colnames(df), "\\(\\s*(.*?)\\s*%")[, 2])
    
    for (i in 1:length(pca_var)) {
      # calculate normalized pca values
      norm_pca <- df[, i] / 100 * pca_var[i]
      #repopulate the dataframe
      df[, i] <- norm_pca
    }
    
    
    
    
    
  }
  
  #check best k for k-means clustering method
  if (return_elbow) {
    return(fviz_nbclust(df, kmeans, method = "silhouette") +
             labs(subtitle = "Elbow method"))
    
  }
  
  # #
  # fviz_nbclust(df, kmeans, method = "silhouette")+
  #   labs(subtitle = "Silhouette method")
  #
  # fviz_nbclust(df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  #   labs(subtitle = "Gap statistic method")
  
  # compute k-means clustering
  set.seed(1)
  res.km <- kmeans(df, cluster_n, nstart = 1000)
  
  # change colnames so it works for our plot
  df12$class <- str_extract(rownames(df12),  'KRA-0\\d+')
  num <- str_extract(rownames(df),  '_\\d+\\.')
  num <- str_remove_all(num, pattern = '\\.')
  df12$label <- paste0(df12$class, num)
  pc1 <- colnames(df12)[1]
  pc2 <- colnames(df12)[2]
  
  colnames(df12) <- c('PC1', 'PC2', 'class', 'label')
  
  # plot nicely
  p <- ggplot(data = df12, aes(label = label)) +
    geom_point(alpha = 1.0,
               aes(
                 x = PC1,
                 y = PC2,
                 col = as.factor(res.km$cluster)
               )) +
    
    
    theme_cowplot() +
    
    labs(x = pc1, y = pc2) +
    scale_color_manual(labels = labels,
                       values = cols,
                       name = "Clone") +
    theme(legend.position = legend_position,
          text = element_text(size = 17),
          axis.text = element_text(size = 15)) 
  
  return(p)
  
  #ggplotly(p)
  
}

draw_pca_double <-
  function(list_files1,
           list_files2,
           list_files3,
           size,
           legend_position) {
    cells <- c(list_files1, list_files2, list_files3)
    
    
    df <- plot_pca(
      cells,
      colorBy = classes,
      PC1 = 1,
      PC2 = 2,
      plot = F
    )
    
    df$class <- str_extract(rownames(df),  'KRA-0\\d+')
    num <- str_extract(rownames(df),  '_\\d+\\.')
    num <- str_remove_all(num, pattern = '\\.')
    df$label <- paste0(df$class, num)
    pc1 <- colnames(df)[1]
    pc2 <- colnames(df)[2]
    
    colnames(df) <- c('PC1', 'PC2', 'class', 'label')
    
    
    p <- ggplot(data = df, aes(label = label)) +
      geom_point(size = size, aes(x = PC1,
                                  y = PC2,
                                  col = class)) +
      # scale_color_manual(values = c("#FFDB6D", "#00AFBB")) +
      scale_color_manual(
        name = '',
        values = c("#999999", "#D69C4E", '#d65c4e'),
        labels = c('Baseline', 'Recurrence Cycle 1', 'Recurrence Cycle 2')
      ) +
      
      # or consider '#9e1303' for second cycle of recurrence
      
      theme_cowplot() +
      theme(legend.position = legend_position,
            text = element_text(size = 17),
            axis.text = element_text(size = 15)) +
      
      
      labs(x = pc1, y = pc2)
    return(p)
    
    # ggplotly(p)
    
  }


k_cluster_double <- function(list_files1,
                             list_files2,
                             list_files3,
                             
                             cluster_n,
                             cols,
                             labels,
                             legend_position,
                             normalize,
                             return_elbow = F) {
  
  require(factoextra)
  
  cells <- c(list_files1, list_files2, list_files3)
  
  
  df12 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 1,
    PC2 = 2,
    plot = F
  )
  
  
  df34 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 3,
    PC2 = 4,
    plot = F
  )
  
  df56 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 5,
    PC2 = 6,
    plot = F
  )
  
  df78 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 7,
    PC2 = 8,
    plot = F
  )
  
  df910 <- plot_pca(
    cells,
    colorBy = classes,
    PC1 = 9,
    PC2 = 10,
    plot = F
  )
  
  
  df <- cbind(df12, df34, df56, df78, df910)
  
  
  if (normalize) {
    # extract variance explained for each pca
    pca_var <-
      as.numeric(str_match(colnames(df), "\\(\\s*(.*?)\\s*%")[, 2])
    
    for (i in 1:length(pca_var)) {
      # calculate normalized pca values
      norm_pca <- df[, i] / 100 * pca_var[i]
      #repopulate the dataframe
      df[, i] <- norm_pca
    }
    
    
    
    
    
  }
  
  #check best k for k-means clustering method
  if (return_elbow) {
    return(fviz_nbclust(df, kmeans, method = "silhouette") +
             labs(subtitle = "Silhouette method"))
    
  }
  
  # #
  # fviz_nbclust(df, kmeans, method = "silhouette")+
  #   labs(subtitle = "Silhouette method")
  #
  # fviz_nbclust(df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  #   labs(subtitle = "Gap statistic method")
  
  # compute k-means clustering
  set.seed(1)
  res.km <- kmeans(df, cluster_n, nstart = 1000)
  
  # change colnames so it works for our plot
  df12$class <- str_extract(rownames(df12),  'KRA-0\\d+')
  num <- str_extract(rownames(df),  '_\\d+\\.')
  num <- str_remove_all(num, pattern = '\\.')
  df12$label <- paste0(df12$class, num)
  pc1 <- colnames(df12)[1]
  pc2 <- colnames(df12)[2]
  
  colnames(df12) <- c('PC1', 'PC2', 'class', 'label')
  
  # plot nicely
  p <- ggplot(data = df12, aes(label = label)) +
    geom_point(alpha = 1.0,
               aes(
                 x = PC1,
                 y = PC2,
                 col = as.factor(res.km$cluster)
               )) +
    
    
    theme_cowplot() +
    
    labs(x = pc1, y = pc2) +
    scale_color_manual(labels = labels,
                       values = cols,
                       name = "Clone") +
    theme(legend.position = legend_position,
          text = element_text(size = 17),
          axis.text = element_text(size = 15)) 
  
  p
  
}

  
}
```



## divide_subclone_functions script: 'extract_other_cells', 'extract_square', 'l_g' and 'subclone_classes_for_genomeheatmap' functions

```{r divide_subclone_functions, eval = F,echo = T}
extract_other_cells <- function(kra_name, list_of_subclones) {
  i <- which(names(man_select_files_edivisive) == kra_name)
  all <-  str_extract(man_select_files_edivisive[[i]],  '_\\d+\\.') %>% str_remove('_') %>% str_remove('\\.') 
  rest <- all[which(!all %in% list_of_subclones)]
  return(rest)
}


extract_square <- function(list_files1, list_files2, square, x, y) {
  # extracts all cells that lie within a square of a pca plot defined by 
  # user. For example square c(0.1, 0.0) will extract all cells with
  # pc1 lower or higher that 0.1 and pc2 lower or higher than 0.0. User has to rearange functon
  # if he wants x lower or higher than 0.1
  cells <- c(list_files1, list_files2)
  
  df12 <- plot_pca(cells,
                   colorBy = classes, 
                   PC1=1, 
                   PC2=2,
                   plot = F)
  
  colnames(df12) <- c('PC1', 'PC2')
  
  
  # extracting dataframe with correct square
  if(x == '<' & y == '<') {
    df12 <- subset(df12, PC1 < square[1] & PC2 < square[2])
  }
  
  if(x == '<' & y == '>') {
    df12 <- subset(df12, PC1 < square[1] & PC2 > square[2])
  }
  
  if(x == '>' & y == '<') {
    df12 <- subset(df12, PC1 > square[1] & PC2 < square[2])
  }
  
  if(x == '>' & y == '>') {
    df12 <- subset(df12, PC1 > square[1] & PC2 > square[2])
  }
  
  # numbers is: 
  cell_id <-  str_extract(rownames(df12),  '_\\d+\\.') %>% str_remove('_') %>% str_remove('\\.')  
  
  return(cell_id)
  
}

l_g <- function(x, kra_num, list_cells) {
  select <- grepl(paste0(kra_num,'_',x,"\\."), list_cells)
  i <- which(select)
  return(list_cells[i])
  
  
}


subclone_classes_for_genomeheatmap <- function(list_of_subclones, cline) {
  #' @param 
  #' list of subclones is the full list of rda files that have been assigned a subclone_classes_for_genomeheatmap
  #' cline is the line (hub005, hub183 etc.)
  #' rad is either prerad or rad
  #' @return 
  #' returns a vector with that assigns a subclone
  
  extract_subclones <- list_of_subclones[grepl(names(list_of_subclones), pattern = paste0(cline))]
  
  size_subclones <- lapply(extract_subclones, length)
  
  classes <- rep(names(size_subclones), size_subclones)
  
  df <- data.frame(path = unlist(extract_subclones),
                   class = classes)
  
  return(df)
  
  
}


```

## plot_genomeheatmap script: 'genomeheatmap' function
```{r plot_genomeheatmap.R, eval = F,echo = T}
genomeheatmap <- function(selected.files, 
                          path, 
                          classes_daan = NULL, 
                          class.col = NULL, 
                          dendogram = F,
                          daan_colours = T,
                          name) {
  # This code was adapted from the AneuFinder package
  # plots and saves genome heatmap of selected.files
  # @param 
  # selected.files: vector of location of selected files.
  # output path: path were plots should be saved. 
  # name: how you want to name the plot
  
  # get platename
  platename <- str_extract(selected.files[1],  'KRA-0\\d+')
  
  # AneuFinder functions: 
  startTimedMessage <- function(...) {
    
    x <- paste0(..., collapse='')
    message(x, appendLF=FALSE)
    ptm <- proc.time()
    return(ptm)
    
  }
  
  transCoord <- function (gr) 
  {
    cum.seqlengths <- cumsum(as.numeric(seqlengths(gr)))
    cum.seqlengths.0 <- c(0, cum.seqlengths[-length(cum.seqlengths)])
    names(cum.seqlengths.0) <- seqlevels(gr)
    gr$start.genome <- start(gr) + cum.seqlengths.0[as.character(seqnames(gr))]
    gr$end.genome <- end(gr) + cum.seqlengths.0[as.character(seqnames(gr))]
    return(gr)
  }
  
  stopTimedMessage <- function(ptm) {
    
    time <- proc.time() - ptm
    message(" ", round(time[3],2), "s")
    
  }
  
  initializeStates <- function (states) 
  {
    somy.states <- grep("somy", states, value = TRUE)
    somy.numbers <- as.integer(sapply(strsplit(somy.states, "-somy"), 
                                      "[[", 1))
    names(somy.numbers) <- somy.states
    if ("zero-inflation" %in% states) {
      multiplicity <- c(`zero-inflation` = 0, somy.numbers)
    }
    else {
      multiplicity <- somy.numbers
    }
    levels.distributions <- c("delta", "dgeom", "dnbinom", "dbinom")
    distributions <- rep(NA, length(states))
    names(distributions) <- states
    distributions[states == "zero-inflation"] <- "delta"
    distributions[states == "0-somy"] <- "dgeom"
    distributions[(states != "zero-inflation") & (states != "0-somy")] <- "dnbinom"
    states <- factor(states, levels = states)
    distributions <- factor(distributions, levels = levels.distributions)
    l <- list(states = states, distributions = distributions, 
              multiplicity = multiplicity)
    return(l)
  }
  
  #  colours
  if (daan_colours) {
    stateColors <- function(states = c("zero-inflation", paste0(0:10, "-somy"),
                                       "total")) {
      
      state.colors <- c(`zero-inflation` = "#1d4661", `0-somy` = "#1d4661",
                        `1-somy` = "#3787BA", `2-somy` = "#95B8C5",
                        `3-somy` = "#F0ECEB", `4-somy` = "#D7A290", `5-somy` = "#BF583B",
                        `6-somy` = "#8D1128", `7-somy` = "#3C0912", `8-somy` = "black",
                        total = "black")
      
      states.with.color <- intersect(states, names(state.colors))
      cols <- rep("black", length(states))
      names(cols) <- states
      cols[states.with.color] <- state.colors[states.with.color]
      return(cols)
    }
    
  }

  
  
  # heatmapgenomewide adapted form AneuFinder package
  heatmapGenomewide_daan <- function (hmms, ylabels = NULL, classes, reorder.by.class = TRUE, 
                                      classes.color, file = NULL, cluster = TRUE, plot.breakpoints = FALSE, 
                                      hotspots = NULL, exclude.regions = NULL) 
  {
    if (!is.null(ylabels)) {
      if (length(ylabels) != length(hmms)) {
        stop("length(ylabels) must equal length(hmms)")
      }
    }
    if (!is.null(classes)) {
      if (length(classes) != length(hmms)) {
        stop("length(classes) must equal length(hmms)")
      }
    }
    if (length(classes.color) != length(unique(classes))) {
      stop("'classes.color' must have the same length as unique(classes)")
    }
    if (is.null(names(classes.color))) {
      names(classes.color) <- unique(classes)
    }
    if (!setequal(names(classes.color), unique(classes))) {
      stop("The names of 'classes.color' must be equal to the unique elements in 'classes'")
    }
    if (length(hmms) == 1 & cluster == TRUE) {
      cluster <- FALSE
      warning("Cannot do clustering because only one object was given.")
    }
    hmms <- loadFromFiles(hmms, check.class = c("aneuHMM", "aneuBiHMM"))
    class.data <- data.frame(ID = sapply(hmms, "[[", "ID"))
    class.data$ID <- factor(class.data$ID, levels = class.data$ID)
    if (is.null(ylabels)) {
      class.data$ylabel <- as.character(class.data$ID)
    }
    else {
      class.data$ylabel <- as.character(ylabels)
    }
    class.data$class <- classes
    mapping <- class.data$ylabel
    names(mapping) <- class.data$ID
    if (reorder.by.class) {
      cl <- clusterHMMs(hmms, cluster = cluster, classes = classes, 
                        exclude.regions = exclude.regions)
    }
    else {
      cl <- clusterHMMs(hmms, cluster = cluster, exclude.regions = exclude.regions)
    }
    hmms <- hmms[cl$IDorder]
    class.data <- class.data[cl$IDorder, ]
    class.data$ID <- factor(class.data$ID, levels = class.data$ID)
    segments.list <- GRangesList()
    for (i1 in 1:length(hmms)) {
      hmm <- hmms[[i1]]
      if (is.null(hmm$segments)) {
        segments.list[[hmm$ID]] <- GRanges()
      }
      else {
        segments.list[[hmm$ID]] <- hmm$segments
      }
    }
    if (plot.breakpoints) {
      breakpoints <- GRangesList()
      for (i1 in 1:length(hmms)) {
        hmm <- hmms[[i1]]
        if (is.null(hmm$breakpoints)) {
          breakpoints[[hmm$ID]] <- GRanges()
        }
        else {
          breakpoints[[hmm$ID]] <- hmm$breakpoints
        }
      }
      if (length(breakpoints) == 0) {
        plot.breakpoints <- FALSE
      }
    }
    ptm <- startTimedMessage("Transforming coordinates ...")
    segments.list <- endoapply(segments.list, transCoord)
    if (plot.breakpoints) {
      breakpoints <- endoapply(breakpoints, transCoord)
    }
    stopTimedMessage(ptm)
    ptm <- startTimedMessage("Making the plot ...")
    df <- list()
    for (i1 in 1:length(segments.list)) {
      df[[length(df) + 1]] <- data.frame(start = segments.list[[i1]]$start.genome, 
                                         end = segments.list[[i1]]$end.genome, seqnames = seqnames(segments.list[[i1]]), 
                                         ID = names(segments.list)[i1], state = segments.list[[i1]]$state)
    }
    df <- do.call(rbind, df)
    df$ID <- factor(df$ID, levels = levels(class.data$ID))
    df$ylabel <- mapping[as.character(df$ID)]
    if (plot.breakpoints) {
      df.breakpoints <- list()
      for (i1 in 1:length(breakpoints)) {
        if (length(breakpoints[[i1]]) > 0) {
          df.breakpoints[[length(df.breakpoints) + 1]] <- data.frame(start = breakpoints[[i1]]$start.genome, 
                                                                     end = breakpoints[[i1]]$end.genome, seqnames = seqnames(breakpoints[[i1]]), 
                                                                     ID = names(segments.list)[i1], mid = (breakpoints[[i1]]$start.genome + 
                                                                                                             breakpoints[[i1]]$end.genome)/2)
        }
        else {
          df.breakpoints[[length(df.breakpoints) + 1]] <- data.frame(start = numeric(), 
                                                                     end = numeric(), seqnames = character(), ID = character(), 
                                                                     mid = numeric())
        }
      }
      df.breakpoints <- do.call(rbind, df.breakpoints)
      df.breakpoints$ID <- factor(df.breakpoints$ID, levels = levels(class.data$ID))
      df.breakpoints$ylabel <- mapping[as.character(df.breakpoints$ID)]
    }
    cum.seqlengths <- cumsum(as.numeric(seqlengths(segments.list[[1]])))
    names(cum.seqlengths) <- seqlevels(segments.list[[1]])
    cum.seqlengths.0 <- c(0, cum.seqlengths[-length(cum.seqlengths)])
    names(cum.seqlengths.0) <- seqlevels(segments.list[[1]])
    label.pos <- round(cum.seqlengths.0 + 0.5 * seqlengths(segments.list[[1]]))
    df.chroms <- data.frame(y = c(0, cum.seqlengths), x = 1, 
                            xend = length(segments.list))
    pltlist <- list()
    widths <- vector()
    df$state <- factor(df$state, levels = names(sort(initializeStates(levels(df$state))$multiplicity)))
    df$x <- as.numeric(df$ID)
    ggplt <- ggplot(df) + geom_linerange(aes_string(ymin = "start", 
                                                    ymax = "end", x = "x", col = "state"), size = 5) + scale_y_continuous(breaks = label.pos, 
                                                                                                                          labels = names(label.pos))
    

    # ggplt <- ggplt + scale_x_continuous(name = "",
    #                      breaks = 1:length(unique(df$ylabel)),
    #                      labels = unique(df$ylabel))
    
    ggplt <- ggplt + scale_color_manual(values = stateColors(levels(df$state))) # adding custom colours
    # adjusintg x axis
    ggplt <- ggplt + theme(panel.background = element_blank(), 
                           axis.ticks.x = element_blank(), axis.text.x = element_blank(), 
                           axis.line = element_blank(), axis.title.x = element_blank())
    
    ggplt <- ggplt + geom_segment(aes_string(x = "x", xend = "xend",
                                             y = "y", yend = "y"), data = df.chroms, col = "grey13")
    
    
    
    # adjusting y axis
    ggplt <- ggplt + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(), 
                           axis.line = element_blank(), axis.title.x = element_blank())
    
    # removing legend
    ggplt <- ggplt + theme(legend.position="none")
    
    ggplt <- ggplt + coord_flip()
    
    # removing all axis names
    ggplt <- ggplt + ylab("") + xlab("")
    
    # add numeber of cells sequenced text
    ggplt <- ggplt + annotate("text", 
                              label = paste(length(hmms), 'cells'), 
                              x = length(hmms)/2, 
                              y = 3100000000,
                              angle = 270,
                              size = 50)
    
    # decreasing plot margin
    ggplt <- ggplt + theme(plot.margin = unit(c(0,0,0,0), "cm"))
    
    
    if (plot.breakpoints) {
      df.breakpoints$x <- as.numeric(df.breakpoints$ID)
      ggplt <- ggplt + geom_linerange(data = df.breakpoints, 
                                      mapping = aes_string(x = "x", ymin = "start", ymax = "end"), 
                                      size = 2) + ylab("") + geom_point(data = df.breakpoints, 
                                                                        mapping = aes_string(x = "x", y = "mid"))
    }
    if (!is.null(hotspots)) {
      if (length(hotspots) > 0) {
        df.hot <- as.data.frame(transCoord(hotspots))
        df.hot$xmin <- 0
        df.hot$xmax <- length(class.data$ID) + 1
        ggplt <- ggplt + geom_rect(data = df.hot, mapping = aes_string(xmin = "xmin", 
                                                                       xmax = "xmax", ymin = "start.genome", ymax = "end.genome", 
                                                                       alpha = "num.events"), fill = "hotpink4") + scale_alpha_continuous(name = "breakpoints", 
                                                                                                                                          range = c(0.4, 0.8))
      }
    }
    
    
    width.heatmap <- sum(as.numeric(seqlengths(hmms[[1]]$bins)))/3e+09 * 
      150
    height <- max(length(hmms) * 0.5, 2)
    pltlist[["heatmap"]] <- ggplt
    widths["heatmap"] <- width.heatmap
    # adding class colors
    if (!is.null(classes)) {
      width.classes <- 5
      class.data$x <- as.numeric(class.data$ID)
      ggclass <- ggplot(class.data) + geom_linerange(aes_string(ymin = 0, 
                                                                ymax = 1, x = "x", col = "class"), size = 5) + guides(col = FALSE) + 
        xlab("")
      ggclass <- ggclass + theme(panel.background = element_blank(), 
                                 axis.ticks = element_blank(), axis.text = element_blank(), 
                                 axis.line = element_blank(), axis.title.x = element_blank())
      ggclass <- ggclass + coord_flip()
      
      # decreasing plot margin
      ggclass <- ggclass + theme(plot.margin = unit(c(0,0,0,0), "cm"))
      
      if (!is.null(classes.color)) {
        ggclass <- ggclass + scale_color_manual(breaks = names(classes.color), 
                                                values = classes.color)
      }
      pltlist[["classbar"]] <- ggclass
      widths["classbar"] <- width.classes
    }
    # adding dendogram
    if (!is.null(cl$hclust) & dendogram) {
      dhc <- stats::as.dendrogram(cl$hclust)
      ddata <- ggdendro::dendro_data(dhc, type = "rectangle")
      ggdndr <- ggplot(ddata$segments) + geom_segment(aes_string(x = "x", 
                                                                 xend = "xend", y = "y", yend = "yend")) + scale_y_reverse()
      ggdndr <- ggdndr + coord_flip()
      ggdndr <- ggdndr + theme(panel.background = element_blank(), 
                               axis.ticks = element_blank(), axis.text = element_blank(), 
                               axis.line = element_blank(), axis.title = element_blank())
      width.dendro <- 20
      pltlist[["dendro"]] <- ggdndr
      widths["dendro"] <- width.dendro
    }
    # alligning ggpllt with dendogram and classes
    cowplt <- cowplot::plot_grid(plotlist = rev(pltlist), align = "h", 
                                 ncol = length(pltlist), rel_widths = rev(widths))
    
    
    stopTimedMessage(ptm)
    if (!is.null(file)) {
      ptm <- startTimedMessage("Plotting to file ", file, " ...")
      ggsave(file, cowplt, width = sum(widths), height = height, 
             units = "cm", limitsize = FALSE)
      stopTimedMessage(ptm)
    }
    else {
      return(cowplt)
    }
  }
  
  #make heatmap and safe
  suppressWarnings(heatmapGenomewide_daan(selected.files, classes = classes_daan, classes.color = class.col,
                         file = paste0(path, '/', name, '_', platename, '.pdf')))
  
  return(print(paste0(name, ' done.')))
  
}
  

```

## fisher_test script: 'perform_fisher' function 
```{r fisher_test.R, eval = F,echo = T}

perform_fisher <- function(dataframe,
                           population1,
                           population2) {
  #' @param 
  #' dataframe is a df with columns paths and class with values 'hub015_rad_a', 'hub015_prerad_a' etc.
  #' population 1 and population two are the two pops you want to compare, for example prerad vs rad
  #' or prerad versus rad cycle 2
  #' @return
  #' returns the p value of a Fisher's exact test. If the p value is above 0.05, the distributions
  #' pre and post rad are the same. 
  #' 
  
  dataframe$rad <- ifelse(dataframe$class %in% population1, 'pop1',
                          ifelse(dataframe$class %in% population2, 'pop2',
                                 NA))
  
  org_id <- unique(str_extract(unique(dataframe$class), 'hub\\d{3}'))
  
  # remove na
  dataframe <- dataframe[which(!is.na(dataframe$rad)),]
  
  simple_fun <- function(string) {
    return(tail(string,1))
  }
  
  dataframe$clone <- unlist(lapply(stringr::str_split(dataframe$class, pattern = '_'), simple_fun))
  
  # in hub015 and hub005, we defined subclones. These are actually part of the same clone, so should be 
  # analysed together
  if (org_id %in% c('hub005', 'hub015')){
    dataframe$clone <- str_replace_all(dataframe$clone, pattern = 'a.a|a.b', replacement = 'a')
    
  }
  
  tab <- table(dataframe$clone, dataframe$rad)
  
  
  # df <- data.frame(cline <- org_id, p_val <- fisher.test(tab)$p.value)
  # 
  # return(df) 
  return(fisher.test(tab)$p.value)
  
}

  

```

## find_specific_cna_sc script: 'find_specific_cna_sc' function 
```{r find_specific_cna_sc, eval = F,echo = T}
find_specific_cna_sc <-
  function(list_resistant,
           list_sensitive,
           perc_cutoff_within_subclone_resistant,
           perc_cutoff_within_subclone_sensitive,
           per_cutoff_across_subclone_resistant,
           per_cutoff_across_subclone_sensitive,
           return_cnas_per_subclone = F) {
    #' @param list_resistant a list subclone names which itself contains a list of paths of paths to aneuHMM .Rda files. 
    #' @param list_sensitive a list subclone names which itself contains a list of paths of paths to aneuHMM .Rda files. 
    #' @param perc_cutoff_within_subclone_resistant user defined percentage cutoff to use (e.g. 0.6 means a certain CNA is shared by 60% of the cells
    #' within a subclone).
    #' @param perc_cutoff_within_subclone_senstive same as in perc_cutoff_within_subclone_resistant but for the sensitive group
    #' @param per_cutoff_across_subclone_resistant user defined percentage cutoff to use (e.g. 0.7 means a certain CNA is shared in 70% of all subclones)
    #' @param return_cnas_per_subclone boolean. If TRUE will return the shared by perc_cutoff_within_subclone CNAs for each list of each item within 
    #' list_resistant. Note list_sensitive should be set to NULL for proper results!!
    #' @param per_cutoff_across_subclone_sensitive same as resistant but for the sensitive group
    #' @example perc_cutoff_within_subclone = 0.6 and per_cutoff_across_subclone = 0.7 means the algorithm will find CNAs that are shared 
    #' by 60% of single cells within each subclone, and by 70% of all subclones. Important, a cutoff of 50% is the same as computing the median.
    #' @return a list of GRanges showing unique to list_resistant amplifications and deletions and unique to list_sensitive
    #' amplifications and deletions or, if return_cnas_per_subclone see param return_cnas_per_subclone above.
    #' @details Note that this algorithm is NOT sensitive to the number of single cells within each subclone. 
    
    #############
    # Libraries #
    #############
    require(plyranges)
    require(AneuFinder)
    
    ###########
    # Part 1. #
    ###########
    print('Computing (this may take some minutes)...')
    
    resistant_sc <-
      lapply(list_resistant,
             loadFromFiles,
             check.class = c("aneuHMM", "aneuBiHMM"))
    sensitive_sc <-
      lapply(list_sensitive,
             loadFromFiles,
             check.class = c("aneuHMM", "aneuBiHMM"))
    
    # find specific CNAs needs a list of GRanges where each GRange has columns
    # seqnames, ranges, strand (not necessary) and cn.
    wrangle_sc <- function(list_lff) {
      # segments is the reduced bins GRange (so all equal CN bins put together)
      wrangle_within <- function(list_lff_within) {
        segments <- list_lff_within$segments
        # ugly way of adding a cn column
        segments$cn <- segments$copy.number
        
        return(segments)
        
        # END of wrange_within function
        
      }
      within_subcl <- lapply(list_lff, wrangle_within)
      
      # END OF wrangle_sc function
      
    }

    list_resistant <- lapply(resistant_sc, wrangle_sc)
    list_sensitive <- lapply(sensitive_sc, wrangle_sc)
    
    print('Extracted segment info from files')
    Sys.sleep(1) 
    
    ###########
    # Part 2. #
    ###########
    # The Granges are now still arranged in bins. We are first going to
    # combine bins with similar copy number.
    print('Computing (this may take some minutes)...')
    combine_indels <- function(subclone_consensus) {
      #' @param subclone_consensus_list is a GRanges with seqnames, ranges, strand and cn
      #' @returns list of Granges where each Granges has only CNA of cn2 or cn>2
      
      combine_within <- function(subclone_consensus_within) {
        # subset subclone_consensus in cn <2, cn = 2 and cn > 2
        cn_less_2 <-
          subclone_consensus_within[subclone_consensus_within$cn < 2,]
        cn_more_2 <-
          subclone_consensus_within[subclone_consensus_within$cn > 2,]
        
        # reduce each GRanges (joins consecutive ranges together)
        cn_less_2 <- reduce(cn_less_2)
        cn_more_2 <- reduce(cn_more_2)
        
        # reduce deletes metadata.
        # adding metadata
        cn_less_2$cn <- rep('<2', length(cn_less_2))
        
        cn_more_2$cn <- rep('<2', length(cn_more_2))
        
        # make list and rename items
        GR_list <- GRangesList(cn_less_2, cn_more_2)
        names(GR_list) <- c('<2', '>2')
        
        # Return #
        return(GR_list)
      }
      
      combine_subcl <- lapply(subclone_consensus, combine_within)
      
    }
    
    # run an apply function here on each Granges in list_resistant versus list_sensitive
    resistant_split <- lapply(list_resistant, combine_indels)
    sensitive_split <- lapply(list_sensitive, combine_indels)
    
    # splits deletions together within each subclone
    grouper_del <- function(gr) {
      grouper_within <- function(gr_within) {
        return(gr_within$'<2')
      }
      
      within_grouper <- lapply(gr, grouper_within)
    }
    
    # splits amplifciations together within each subclone
    grouper_ampl <- function(gr) {
      grouper_within <- function(gr_within) {
        return(gr_within$'>2')
      }
      
      within_grouper <- lapply(gr, grouper_within)
    }
    
    # run apply on each subclone
    resistant_split_del <- lapply(resistant_split, grouper_del)
    resistant_split_ampl <- lapply(resistant_split, grouper_ampl)
    
    sensitive_split_del <- lapply(sensitive_split, grouper_del)
    sensitive_split_ampl <- lapply(sensitive_split, grouper_ampl)
    
    ###########
    # Part 3. #
    ###########
    # Part 3A #
    ###########
    # Finding common CNAs within each subclone
    shared_cnas <-
      function(list_GRanges,
               perc_cutoff_within_subclone) {
        #' @param list_GRanges is a list of GRanges with seqnames, ranges, strand and cn
        #' @param perc_cutoff_within_subclone user defined percentage cutoff to use (e.g. 0.6)
        #' @returns Granges where each Granges is shared by => perc_cutoff_within_subclone
        
        # finding overlaps in x% of regions: wait for response community:
        # https://stackoverflow.com/questions/74900085/find-ranges-that-are-shared-by-80-or-more-of-10-granges-objects
        # https://support.bioconductor.org/p/9148540/
        
        shared_cnas_within <- function(list_GRanges_within) {
          n <- length(list_GRanges_within) # number of range sets
          shared_cna <-
            bind_ranges(list_GRanges_within, .id = "origin") %>%
            compute_coverage() %>%
            mutate(fraction_cov = score / n) %>%
            filter(fraction_cov >= perc_cutoff_within_subclone) %>%
            reduce_ranges()
          
          return(shared_cna)
        }
        
        lapply(list_GRanges, shared_cnas_within)
      }
    
    resistant_shared_del <-
      shared_cnas(resistant_split_del, perc_cutoff_within_subclone = perc_cutoff_within_subclone_resistant)
    resistant_shared_ampl <-
      shared_cnas(resistant_split_ampl, perc_cutoff_within_subclone = perc_cutoff_within_subclone_resistant)
    sensitive_shared_del <-
      shared_cnas(sensitive_split_del, perc_cutoff_within_subclone = perc_cutoff_within_subclone_sensitive)
    sensitive_shared_ampl <-
      shared_cnas(sensitive_split_ampl, perc_cutoff_within_subclone = perc_cutoff_within_subclone_sensitive)
    
    # END of function if return_cnas_per_subclone == T
    if (return_cnas_per_subclone == T) {
      cna_list <- list (deletions = c(resistant_shared_del, sensitive_shared_del), 
                        amplifications = c(resistant_shared_ampl, sensitive_shared_del))
      
      print(
        paste0(
          'Extracted CNAs that are shared by ',
          as.numeric(perc_cutoff_within_subclone_resistant) * 100,
          '% of single cells within each resistant subclone, and by ',
          as.numeric(perc_cutoff_within_subclone_sensitive) * 100,
          '% of single cells within each sensitive subclone'
        )
      )
      ##########
      # Unload #
      ##########
      suppressWarnings(invisible(lapply(paste0("package:", names(sessionInfo()$otherPkgs)),   # Unload add-on packages
                                        detach,
                                        character.only = TRUE, unload = TRUE)))
      
      return(cna_list)
    }
    
    # Part 3B #
    ###########
    # Finding common CNAs across subclones
    shared_cnas_across_subclones <-
      function(list_GRanges,
               per_cutoff_across_subclone) {
        #' @param list_GRanges is a list of GRanges with seqnames, ranges, strand and cn
        #' @param perc_cutoff user defined percentage cutoff to use (e.g. 0.6)
        #' @returns Granges where each Granges is shared by => perc_cutoff_within_subclone
        
        # finding overlaps in x% of regions: wait for response community:
        # https://stackoverflow.com/questions/74900085/find-ranges-that-are-shared-by-80-or-more-of-10-granges-objects
        # https://support.bioconductor.org/p/9148540/
        
        n <- length(list_GRanges) # number of range sets
        shared_cna <-
          bind_ranges(list_GRanges, .id = "origin") %>%
          compute_coverage() %>%
          mutate(fraction_cov = score / n) %>%
          filter(fraction_cov >= per_cutoff_across_subclone) %>%
          reduce_ranges()
        
        return(shared_cna)
        
      }
    
    resistant_shared_del_across <-
      shared_cnas_across_subclones(resistant_shared_del, per_cutoff_across_subclone = per_cutoff_across_subclone_resistant)
    resistant_shared_ampl_across <-
      shared_cnas_across_subclones(resistant_shared_ampl, per_cutoff_across_subclone = per_cutoff_across_subclone_resistant)
    sensitive_shared_del_across <-
      shared_cnas_across_subclones(sensitive_shared_del, per_cutoff_across_subclone = per_cutoff_across_subclone_sensitive)
    sensitive_shared_ampl_across <-
      shared_cnas_across_subclones(sensitive_shared_ampl, per_cutoff_across_subclone = per_cutoff_across_subclone_sensitive)
    
    print(
      paste0(
        'Extracted CNAs that are shared by ',
        as.numeric(perc_cutoff_within_subclone_resistant) * 100, ' and ', as.numeric(perc_cutoff_within_subclone_sensitive) * 100,
        '% of single cells within resistant and sensitive subclones, respectively, and that are shared by ',
        as.numeric(per_cutoff_across_subclone_resistant) * 100, ' and ', as.numeric(per_cutoff_across_subclone_sensitive) * 100, 
        '% across resistant and sensitive subclones, respectively.'
      )
    )
    
    Sys.sleep(1) 
    print('Computing (few seconds)...')
    Sys.sleep(2) 
    
    ###########
    # Part 4. #
    ###########
    # Now that we have shared CNAs across subclones with the resistant and sensitive group, we need to extract
    # only those CNAs that are unique to the resistant group.
    
    # unique to resistant lines deletions:
    unique_resistant_del <-
      setdiff(resistant_shared_del_across, sensitive_shared_del_across)
    # unique to resistant lines amplifications
    unique_resistant_ampl <-
      setdiff(resistant_shared_ampl_across,
              sensitive_shared_ampl_across)
    
    # unique to sensitive lines deletions:
    unique_sensitive_del <-
      setdiff(sensitive_shared_del_across, resistant_shared_del_across)
    # unique to sensitive lines amplifications:
    unique_sensitive_ampl <-
      setdiff(sensitive_shared_ampl_across,
              resistant_shared_ampl_across)
    
    print(
      'Identified amplifications and deletions that are unique to resistant or sensitive subclones'
    )
    
    ##########
    # Return #
    ##########
    returner <-
      list(
        unique_resistant_del,
        unique_resistant_ampl,
        unique_sensitive_del,
        unique_sensitive_ampl
      )
    names(returner) <-
      c(
        'unique_resistant_del',
        'unique_resistant_ampl',
        'unique_sensitive_del',
        'unique_sensitive_ampl'
      )
    
    ##########
    # Unload #
    ##########
    suppressWarnings(invisible(lapply(paste0("package:", names(sessionInfo()$otherPkgs)),   # Unload add-on packages
                     detach,
                     character.only = TRUE, unload = TRUE)))
    
    return(returner)
  }

```


## get_cytoband_coverage script: 'get_cytoband_coverage' function 
```{r get_cytoband_coverage.R, eval = F,echo = T}
get_cytoband_coverage <- function(Grange) {
  #' @param Grange a grange with seqnames and granges.
  #' @returns returns a GRange with cytogenetic locations including
  #' percentage of overlap and a dataframe containing information on how much of
  #' the total arm was affected.
  
  #############
  # Libraries #
  #############
  require(tidyverse)
  require(plyranges)
  
  ########
  # Data #
  ########
  # Uncomment me, this is to download cytogenetic coordinates
  # library(biovizBase)
  # hg38IdeogramCyto <- getIdeogram("hg38", cytobands = TRUE)
  # save(hg38IdeogramCyto, file = 'rda/cna_analysis/hg38IdeogramCyto.rda')
  
  # !!! ADDING ../cna_analysis for publication in GitHub !!!
  load('../cna_analysis/rda/cna_analysis/hg38IdeogramCyto.rda')
  
  
  ###########
  # Wrangle #
  ###########
  # Convert both GRanges to similar karyogram style
  seqlevelsStyle(Grange) <- "NCBI"
  seqlevelsStyle(hg38IdeogramCyto) <- "NCBI"
  
  Grange_list_cytoband <- list()
  Grange_list_pq_affected <- list()
  
  # return empty Grange and empty data.frame if Grange is empty
  if (length(Grange) == 0) {
    # return empty Grange
    return(list(GRanges(
      seqnames = character(0),
      IRanges(start = integer(0), end = integer(0)),
      cytobands_cov =  character(0)
    ),
    data.frame(seqnames = character(), 
               start_of_arm = numeric(), 
               end_of_arm = numeric(), 
               width_of_arm = numeric(), 
               strand = character(), 
               chromosome = character(), 
               arm = character(), 
               percentage_arm_affected = numeric(), 
               stringsAsFactors = FALSE)
    ))
  }
  
  for (row in 1:length(Grange)) {
    for_range <- Grange[row]
    
    ##########
    # Part 1 #
    ##########
    ## First find specific cytoband locations
    # finding overlaps
    hits <- findOverlaps(for_range, hg38IdeogramCyto)
    
    # computing percentage overlap
    overlaps <-
      pintersect(for_range[queryHits(hits)], hg38IdeogramCyto[subjectHits(hits)])
    percentOverlap <-
      width(overlaps) / width(hg38IdeogramCyto[subjectHits(hits)])
    
    # extracting cytobands
    cytobands <-
      paste0(seqnames(hg38IdeogramCyto[subjectHits(hits)]), hg38IdeogramCyto[subjectHits(hits)]$name)
    # replace 'chr'
    cytobands <-
      str_replace(cytobands, pattern = 'chr', replacement = '')
    
    cytobands_cov <-
      list(paste0(cytobands, ';', round(percentOverlap, 2) * 100, '%'))
    
    for_range$cytobands_cov <- cytobands_cov
    
    Grange_list_cytoband[[row]] <- for_range
    
    ##########
    # Part 2 #
    ##########
    # make dataframe that shows how much of an arm is affected 
    
    # Grange with p and q IRanges
    p_q <- hg38IdeogramCyto
    
    p_q$arm <- str_extract(p_q$name, 'p|q')
    
    p_q <- subset(p_q, seqnames %in% c(seq(1:22), 'X', 'Y'))
    
    p_q <- p_q %>% group_by(seqnames, arm) %>% reduce_ranges()
    
    # finding overlaps
    hits_pq <- findOverlaps(for_range, p_q)
    
    # computing percentage overlap
    overlaps <-
      pintersect(for_range[queryHits(hits_pq)], p_q[subjectHits(hits_pq)])
    percentOverlap <-
      width(overlaps) / width(p_q[subjectHits(hits_pq)])
    
    p_q_percentage <- as.data.frame(p_q[subjectHits(hits_pq)])
    
    p_q_percentage$percentage_arm_affected <- percentOverlap * 100
    
    colnames(p_q_percentage) <-
      c(
        'seqnames',
        'start_of_arm',
        'end_of_arm',
        'width_of_arm',
        'strand',
        'chromosome',
        'arm',
        'percentage_arm_affected'
      )
    
    
    
    
    Grange_list_pq_affected[[row]] <- p_q_percentage
    
    
  }
  
  Grange <- bind_ranges(Grange_list_cytoband)
  pq_arm_affect <- bind_rows(Grange_list_pq_affected)
  
  return(list(Grange, pq_arm_affect))
  
  ### END of function ###
  
}

```

## get_genes script: 'get_genes' functoin
```{r get_genes, eval = F,echo = T}
get_genes <- function(GRange) { 
  #' @param Grange a grange with seqnames and granges. 
  #' @returns returns df with all genes encoded within the GRange regions. 
  
  require(GenomicRanges)
  require(biomaRt)
  
  # This code should be run only once and is therefore commented. 
  # code from: https://www.biostars.org/p/311199/
  
  # Set up an gene annotation template to use
  # mart <- useMart(biomart="ensembl", dataset="hsapiens_gene_ensembl")
  # mart <- useMart(biomart="ENSEMBL_MART_ENSEMBL", host="www.ensembl.org", path="/biomart/martservice", dataset="hsapiens_gene_ensembl")
  # genes <- getBM(attributes=c("hgnc_symbol","chromosome_name","start_position","end_position"), mart=mart)
  # genes <- genes[genes[,1]!="" & genes[,2] %in% c(1:22,"X","Y"),]
  # xidx <- which(genes[,2]=="X")
  # yidx <- which(genes[,2]=="Y")
  # genes[xidx, 2] <- 23
  # genes[yidx, 2] <- 24
  # genes[,2] <- sapply(genes[,2],as.integer)
  # genes <- genes[order(genes[,3]),]
  # genes <- genes[order(genes[,2]),]
  # save(genes, file = 'rda/cna_analysis/genes.rda')
  # colnames(genes) <- c("GeneSymbol","Chr","Start","End")
  # genes_GR <- makeGRangesFromDataFrame(genes,keep.extra.columns = TRUE)
  # save(genes_GR, file = 'rda/cna_analysis/genes_GR.rda')
  
  # loading genelist and genomic location
  load("../cna_analysis/rda/cna_analysis/genes_GR.rda", envir = .GlobalEnv)
  load('../cna_analysis/rda/cna_analysis/genes.rda', envir = .GlobalEnv )
  
  # Convert both GRanges to similar karyogram style
  seqlevelsStyle(GRange) <- "UCSC"
  GRange <- renameSeqlevels(GRange, paste0('chr', c(1:23)))
  
  seqlevelsStyle(genes_GR) <- "UCSC"
  
  # Finding hits with genes_GR and GRanges
  hits <- findOverlaps(genes_GR, GRange, type="within")
  
  # constructing
  df <- cbind(as.data.frame(GRange)[subjectHits(hits),],genes[queryHits(hits),])
  
  return(df)
  
}

```

## get_oncogenes scripts: 'get_oncogenes' function
```{r get_oncogenes, eval = F,echo = T}
get_oncogenes <- function(GRange) {
  #' @param Grange a grange with seqnames and granges. 
  #' @returns returns df with all genes encoded within the GRange regions. 
  source('R/get_genes.R')
  
  # first finding all genes within GRange
  all_genes <- get_genes(GRange) 
  
  # change colnames so dataframes match
  colnames(all_genes)[which(names(all_genes) == 'hgnc_symbol')] <- "Gene Symbol"   
  
  # downloading oncogenes
  require(readr)
  oncogenes <- read_csv("../cna_analysis/data/cna_analysis/Census_allMon May 30 12_43_01 2022.csv")
  
  
  # subset df_genes so to only have oncogenes
  require(tidyverse)
  oncogenes <- inner_join(oncogenes, all_genes)
  
  return(oncogenes)
  
}

```


## plot_genes_karyotype script: 'plot_genes_karyotype' function
```{r plot_genes_karyotype, eval = F,echo = T}
plot_genes_karyotype <-
  function(GRange,
           dist = -30,
           show_genes,
           show_chromosomes = c(
             "chr1",
             "chr2",
             "chr3",
             "chr4",
             "chr5",
             "chr6",
             "chr7",
             "chr8",
             "chr9",
             "chr10",
             "chr11",
             "chr12",
             "chr13",
             "chr14",
             "chr15",
             "chr16",
             "chr17",
             "chr18",
             "chr19",
             "chr20",
             "chr21",
             "chr22",
             "chrX"
           )) {
    #' @param GRange a GRange with seqnames, ranges, strand and hgnc_symbol
    #' @param dist How far away the genes should be plotted from the lines.
    #' Between -40 and -70 seems to do the trick most of the times.
    #' @param show_genes is a vector of gene symbols to show.
    #' @param show_chromosomes is a vector indicating which chromosomes to show.
    #' @return a karyotype with genes labeled
    #' @details. Throws an error when the GRange does not contain either
    #' ampflications or deletions. This can be ignored, the resulting plot
    #' is correct
    
    #############
    # Libraries #
    #############
    require(karyoploteR)
    require(stringr)
    
    ###########
    # Wrangle #
    ###########
    # making sure seqlevels match
    seqlevelsStyle(GRange) <- 'UCSC'
    
    kp <- plotKaryotype(
      "hg38",
      plot.type = 5,
      labels.plotter = NULL,
      main = "",
      cex = 4,
      chromosomes = show_chromosomes
    )
    
    #renaming seqlevels
    seqlevels_grange_change <-
      str_replace_all(seqlevels(GRange),
                      pattern = 'chr23',
                      replacement = 'chrX')
    
    GRange <- renameSeqlevels(GRange, value = seqlevels_grange_change)
    
    kpAddChromosomeNames(
      kp,
      chr.names = str_remove_all(show_chromosomes, 'chr'),
      cex = 1.3
    )
    
    # split into amplifications and deletions
    ampl <- GRange[GRange$cn == 'amplified']
    ampl <- ampl[ampl$hgnc_symbol %in% show_genes]
    
    del <- GRange[GRange$cn == 'deleted']
    del <- del[del$hgnc_symbol %in% show_genes]
    
    tryCatch(
      cor <-
        cor.test(df$AUC, df$dependency, use = "complete.obs"),
      error = function(e)
        NULL
    )
    
    tryCatch(
      kpPlotMarkers(
        kp,
        data = ampl,
        labels = ampl$hgnc_symbol,
        ignore.chromosome.ends = T,
        r0 = 1,
        r1 = 0.85,
        label.dist = 0.003,
        label.margin = dist,
        marker.parts = c(0.3, 0.1, 0.1),
        line.color = 'firebrick',
        label.color = 'firebrick'
      ),
      error = function(e)
        NULL
    )
    
    
    tryCatch(
      kpPlotMarkers(
        kp,
        data = del,
        labels = del$hgnc_symbol,
        ignore.chromosome.ends = T,
        r0 = 1,
        r1 = 0.4,
        label.dist = 0.003,
        cex = 8,
        label.margin = dist,
        marker.parts = c(0.3, 0.1, 0.1),
        line.color = 'steelblue',
        label.color = 'steelblue'
      ),
      error = function(e)
        NULL
    )
    
    
  }


```


```{r 4, eval = F,echo = T}

```