[["source-code.html", "6 Source code 6.1 AUC_rad script: ‘AUC_fun’ function 6.2 fitter_rad script: ‘fitter’ function 6.3 ic50_rad script: ‘IC50_fun’ function 6.4 relativize_dr script: ‘relative’ function 6.5 quality_functions script: ‘quality_check’, ‘quality_select’ and ‘check_quality’ functions 6.6 plot_pca_kmeans script: ‘draw_pca’, ‘k_cluster’, ‘draw_pca_double’ and ‘k_cluster_double’ functions 6.7 divide_subclone_functions script: ‘extract_other_cells’, ‘extract_square’, ‘l_g’ and ‘subclone_classes_for_genomeheatmap’ functions 6.8 plot_genomeheatmap script: ‘genomeheatmap’ function 6.9 fisher_test script: ‘perform_fisher’ function 6.10 find_specific_cna_sc script: ‘find_specific_cna_sc’ function 6.11 get_cytoband_coverage script: ‘get_cytoband_coverage’ function 6.12 get_genes script: ‘get_genes’ functoin 6.13 get_oncogenes scripts: ‘get_oncogenes’ function 6.14 plot_genes_karyotype script: ‘plot_genes_karyotype’ function 6.15 shifters script: ‘create_cn_matrix’ and ‘cluster_and_shift_transitions’ functions 6.16 calculate_heterogeneity_score script: ‘calculate_heterogeneity_score’ function 6.17 cna_profiler script: ‘cna_profiler’ function 6.18 cin_signature_ccle script: ‘run_cin_ccle’ function", " 6 Source code The source code in this here is arranged in a loose chronological order, reflecting the sequence in which it is called in the scripts presented throughout this book. 6.1 AUC_rad script: ‘AUC_fun’ function # returns the AUC of the actual data. AUC_fun &lt;- function(df) { # defining variables to work with d &lt;- df lines &lt;- character() # for loop, checks if CF$cline is in vector lines, if so, do nothing, else append to vector. for (line in d$cline) ( ifelse(line %in% lines, NA, lines &lt;- c(lines, line))) # separate into dataframes according to cline per_line &lt;- split(d, f = d$cline, drop = TRUE) # define dose_vetor dose_vector &lt;- unique(d$dose) # computes AUC for given predicted survival and dose given by dose_vector AUC_calc &lt;- function(df) { # extract actual data rel_mean &lt;- df$relative_mean # extracts number of experiemnts n &lt;- length(unique(d$Exp)) #remove 2th and 3th number (are duplicates) rel_mean &lt;- rel_mean[seq(1, length(rel_mean), n)] # compute maximal max_AUC &lt;- max(dose_vector)*1 #compute AUC act_AUC &lt;- AUC(x=dose_vector, y = rel_mean) # make dataframe datafr &lt;- data.frame(max_AUC = max_AUC, act_AUC = act_AUC, rel_AUC = act_AUC/max_AUC, expcode = unique(df$expcode), cline= unique(df$cline), treatment = unique(df$treatment ) ) return(datafr) } # Store in vector AUC_vector &lt;- lapply(per_line, AUC_calc) #merge dataframes df = do.call(rbind, AUC_vector) return(df) } 6.2 fitter_rad script: ‘fitter’ function fitter &lt;- function(df) { # defining variables to work with d &lt;- df lines &lt;- character() # for loop, checks if CF$cline is in vector lines, if so, do nothing, else append to vector. for (line in d$cline) ( ifelse(line %in% lines, NA, lines &lt;- c(lines, line))) # separate into dataframes according to cline per_line &lt;- split(d, f = d$cline, drop = TRUE) # Function to make model for every line and dataframe with predicted data for each line. fit_model= function(line) { # line is a dataframe. Outputs the fits of norm and dose fit &lt;- drm(relative ~ dose, # define y -axis (ncolonies) and x-axis (dose) data = line, # defines dataframe fct = LL.4 (names = c(&#39;Slope&#39;, &quot;Lower Limit&quot;, &quot;Upper Limit&quot;, &quot;IC50&quot;))) # defines to fit a log-losistic model) newdata &lt;- expand.grid(dose=exp(seq(log(0.00000001), log(max(df$dose) + 1000), length=1000))) # new data with doses. Note: lowest dose is not # log 0 but log(&#39;very small number&#39;) because otherwise this will hamper the scaling in ggplot later on. pm &lt;- predict(fit, newdata=newdata, interval=&quot;confidence&quot;) # new data with predictions and confidence intervals newdata$pred &lt;- pm[,1] # add prediction values to new data. newdata$predmin &lt;- pm[,2] # add lower bounderies to new data newdata$predmax &lt;- pm[,3] # add upper bounderies to new data newdata$cline &lt;- line$cline[1] # add column with cline. newdata$expcode = unique(df$expcode) return(newdata) } # Store in vector data_frames &lt;- lapply(per_line, fit_model) #merge dataframes df = do.call(rbind, data_frames) return(df) } 6.3 ic50_rad script: ‘IC50_fun’ function IC50_fun &lt;- function(df, rad) { # defining variables to work with ifelse(is.null(rad), d&lt;-df, d &lt;- subset(df, rec_rad == rad)) lines &lt;- character() # for loop, checks if CF$cline is in vector lines, if so, do nothing, else append to vector. for (line in d$cline) ( ifelse(line %in% lines, NA, lines &lt;- c(lines, line))) # separate into dataframes according to cline per_line &lt;- split(d, f = d$cline, drop =TRUE) # Function to make model for every line and dataframe with predicted data for each line. ic50= function(line) { # line is a dataframe. Outputs the fits of norm and dose fit &lt;- drm(relative ~ dose, # define y -axis (ncolonies) and x-axis (dose) data = line, # defines dataframe fct = LL.4 (names = c(&#39;Slope&#39;, &quot;Lower Limit&quot;, &quot;Upper Limit&quot;, &quot;IC50&quot;))) # defines to fit a log-losistic model) return(coef(fit)[4]) } # Store in vector IC50_vector &lt;- lapply(per_line, ic50) #merge dataframes df = do.call(rbind, IC50_vector) return(df) } 6.4 relativize_dr script: ‘relative’ function relative &lt;- function(df, rad) { #&#39; @param df with dose response data and columns cline, dose, Exp, #&#39; rec_rad, expcode, ncolonies #&#39; @param rad if line received radiation (T or F), stored in column rec_rad #&#39; @return relativized data where dose = 0 is used as 100% # defining variables to work with ifelse(rad == T, d&lt;-subset(df, rec_rad == 1), d&lt;-subset(df, rec_rad == 0) ) # define ncolonies column &lt;- &quot;ncolonies&quot; # Extracts the column name. col &lt;- d[c(column)] # extracts number of experiemnts n &lt;- length(unique(d$Exp)) # Takes mean every nth row mean_fun &lt;- function(x) { m &lt;- mean(x, na.rm = TRUE) return(m) } mean &lt;- aggregate(col,list(rep(1:(nrow(col)%/%n+1),each=n,len=nrow(col))), mean_fun)[-1] # Duplicates (n=2) or triplicates (n=3) the rows. mean &lt;- mean[rep(seq_len(nrow(mean)), each = n), ] # Adds everything to the dataframe. d[&quot;mean&quot;] &lt;- mean # Select mean values of 0 concentration d &lt;- d %&gt;% group_by(cline) %&gt;% arrange(cline,dose) first &lt;- d[d$dose==0, ] %&gt;% dplyr::select(cline, value100=mean) # Make cline a factor d$cline&lt;-factor(d$cline) # Merge first original (d) d &lt;- d %&gt;% merge(first,by=c(&quot;cline&quot;)) # Extract only every nth row. d = d[seq(1, nrow(d), n), ] # make new column with relative, called relative d$relative = d$ncolonies/d$value100 d$relative_mean = d$mean/d$value100 d&lt;-subset(d, select=-c(mean,value100)) # compute relative standard error of the mean # define the column with sem in it column &lt;- &quot;relative&quot; # Extracts the column name. col &lt;- d[c(column)] sem_fun &lt;- function(x) { std &lt;- sd(x, na.rm = TRUE) vector &lt;- na.omit(x) sem &lt;- std/sqrt(length(vector)) return(sem) } sem &lt;- aggregate(col,list(rep(1:(nrow(col)%/%n+1),each=n,len=nrow(col))),sem_fun)[-1] sem &lt;- sem[rep(seq_len(nrow(sem)), each = n), ] d[&quot;relative_sem&quot;] &lt;- sem return(d) } 6.5 quality_functions script: ‘quality_check’, ‘quality_select’ and ‘check_quality’ functions quality_check &lt;- function(inputdir, model) { #&#39; @param inputdir is directory containing the standard aneufinder output for each plate #&#39; model is which model to use for the quality check: either dnacopy, edivisive or HMM #&#39; quality_check will make quality metrics for each plate #&#39; quality_check assumes that rdaBaseDirectory contains folder with models for each plate #&#39; each plate folder has to contain a MODEL folder and a method-&#39;dnacopy, edivisive, or HMM&#39; folder #&#39; @example quality_check(inputdir = rdaBaseDirectory, model = &#39;edivisive&#39;) # go to folder with appropiate files rda_folder &lt;- paste0(inputdir, &#39;/MODELS&#39;, &#39;/method-&#39;, model) # extract files rda_files &lt;- list.files(rda_folder, full.names = TRUE) # run quality check on each file cl &lt;- clusterByQuality( rda_files, measures = c( &#39;spikiness&#39;, &#39;num.segments&#39;, &#39;entropy&#39;, &#39;bhattacharyya&#39;, &#39;sos&#39; ) ) return(cl) } quality_select &lt;- function(cl, spik, bhat) { #&#39; selects all files that meets the defined quality requirements #&#39; @param cl output of the clusterByQuality function in AneuFinder #&#39; @param spik the spikiness treshhold. All clusters with spikiness above #&#39; the treshold will be removed #&#39; @param bhat the bhattacharrya score. All clusters with bhattacharrya below #&#39; the treshold will be removed #&#39; @return returns a vector of selected files paths # convert to df to allow easy wrangling cl_df &lt;- as.data.frame(cl$parameters) # remove higher than spik spik &lt;- subset(cl_df, spikiness &lt; spik) # remove lower than bhat spik_bhat &lt;- subset(spik, bhattacharyya &gt; bhat) cluster_n &lt;- nrow(spik_bhat) # create vector of selected files selected.files &lt;- unlist(cl$classification[0:cluster_n]) return(selected.files) } check_quality &lt;- function(cl) { return(cl$parameters) } } 6.6 plot_pca_kmeans script: ‘draw_pca’, ‘k_cluster’, ‘draw_pca_double’ and ‘k_cluster_double’ functions draw_pca &lt;- function(list_files1, list_files2, size, legend_position, baseline_kra, recurrence_kra, ssdna004 = F) { cells &lt;- c(list_files1, list_files2) df &lt;- plot_pca( cells, colorBy = classes, PC1 = 1, PC2 = 2, plot = F ) df$class &lt;- str_extract(rownames(df), &#39;KRA-0\\\\d+&#39;) num &lt;- str_extract(rownames(df), &#39;_\\\\d+\\\\.&#39;) num &lt;- str_remove_all(num, pattern = &#39;\\\\.&#39;) df$label &lt;- paste0(df$class, num) pc1 &lt;- colnames(df)[1] pc2 &lt;- colnames(df)[2] colnames(df) &lt;- c(&#39;PC1&#39;, &#39;PC2&#39;, &#39;class&#39;, &#39;label&#39;) col_vals &lt;- ifelse(ssdna004 == T, list(c(&quot;#D69C4E&quot;, &quot;#999999&quot;)), list(c(&quot;#999999&quot;, &quot;#D69C4E&quot;))) label_vals &lt;- ifelse(ssdna004 == T, list(c(&#39;Recurrence&#39;, &#39;Baseline&#39;)), list(c(&#39;Baseline&#39;, &#39;Recurrence&#39;))) p &lt;- ggplot(data = df, aes(label = label)) + geom_point(size = size, aes(x = PC1, y = PC2, col = class)) + # scale_color_manual(values = c(&quot;#FFDB6D&quot;, &quot;#00AFBB&quot;)) + scale_color_manual( name = &#39;&#39;, values = col_vals[[1]], labels = label_vals[[1]] ) + # or consider &#39;#9e1303&#39; for second cycle of recurrence theme_cowplot() + theme(legend.position = legend_position, text = element_text(size = 17), axis.text = element_text(size = 15)) + labs(x = pc1, y = pc2) p # ggplotly(p) } k_cluster &lt;- function(list_files1, list_files2, cluster_n, cols, labels, legend_position, normalize, return_elbow = F) { require(factoextra) cells &lt;- c(list_files1, list_files2) df12 &lt;- plot_pca( cells, colorBy = classes, PC1 = 1, PC2 = 2, plot = F ) df34 &lt;- plot_pca( cells, colorBy = classes, PC1 = 3, PC2 = 4, plot = F ) df56 &lt;- plot_pca( cells, colorBy = classes, PC1 = 5, PC2 = 6, plot = F ) df78 &lt;- plot_pca( cells, colorBy = classes, PC1 = 7, PC2 = 8, plot = F ) df910 &lt;- plot_pca( cells, colorBy = classes, PC1 = 9, PC2 = 10, plot = F ) df &lt;- cbind(df12, df34, df56, df78, df910) if (normalize) { # extract variance explained for each pca pca_var &lt;- as.numeric(str_match(colnames(df), &quot;\\\\(\\\\s*(.*?)\\\\s*%&quot;)[, 2]) for (i in 1:length(pca_var)) { # calculate normalized pca values norm_pca &lt;- df[, i] / 100 * pca_var[i] #repopulate the dataframe df[, i] &lt;- norm_pca } } #check best k for k-means clustering method if (return_elbow) { return(fviz_nbclust(df, kmeans, method = &quot;silhouette&quot;) + labs(subtitle = &quot;Elbow method&quot;)) } # # # fviz_nbclust(df, kmeans, method = &quot;silhouette&quot;)+ # labs(subtitle = &quot;Silhouette method&quot;) # # fviz_nbclust(df, kmeans, nstart = 25, method = &quot;gap_stat&quot;, nboot = 50)+ # labs(subtitle = &quot;Gap statistic method&quot;) # compute k-means clustering set.seed(1) res.km &lt;- kmeans(df, cluster_n, nstart = 1000) # change colnames so it works for our plot df12$class &lt;- str_extract(rownames(df12), &#39;KRA-0\\\\d+&#39;) num &lt;- str_extract(rownames(df), &#39;_\\\\d+\\\\.&#39;) num &lt;- str_remove_all(num, pattern = &#39;\\\\.&#39;) df12$label &lt;- paste0(df12$class, num) pc1 &lt;- colnames(df12)[1] pc2 &lt;- colnames(df12)[2] colnames(df12) &lt;- c(&#39;PC1&#39;, &#39;PC2&#39;, &#39;class&#39;, &#39;label&#39;) # plot nicely p &lt;- ggplot(data = df12, aes(label = label)) + geom_point(alpha = 1.0, aes( x = PC1, y = PC2, col = as.factor(res.km$cluster) )) + theme_cowplot() + labs(x = pc1, y = pc2) + scale_color_manual(labels = labels, values = cols, name = &quot;Clone&quot;) + theme(legend.position = legend_position, text = element_text(size = 17), axis.text = element_text(size = 15)) return(p) #ggplotly(p) } draw_pca_double &lt;- function(list_files1, list_files2, list_files3, size, legend_position) { cells &lt;- c(list_files1, list_files2, list_files3) df &lt;- plot_pca( cells, colorBy = classes, PC1 = 1, PC2 = 2, plot = F ) df$class &lt;- str_extract(rownames(df), &#39;KRA-0\\\\d+&#39;) num &lt;- str_extract(rownames(df), &#39;_\\\\d+\\\\.&#39;) num &lt;- str_remove_all(num, pattern = &#39;\\\\.&#39;) df$label &lt;- paste0(df$class, num) pc1 &lt;- colnames(df)[1] pc2 &lt;- colnames(df)[2] colnames(df) &lt;- c(&#39;PC1&#39;, &#39;PC2&#39;, &#39;class&#39;, &#39;label&#39;) p &lt;- ggplot(data = df, aes(label = label)) + geom_point(size = size, aes(x = PC1, y = PC2, col = class)) + # scale_color_manual(values = c(&quot;#FFDB6D&quot;, &quot;#00AFBB&quot;)) + scale_color_manual( name = &#39;&#39;, values = c(&quot;#999999&quot;, &quot;#D69C4E&quot;, &#39;#d65c4e&#39;), labels = c(&#39;Baseline&#39;, &#39;Recurrence Cycle 1&#39;, &#39;Recurrence Cycle 2&#39;) ) + # or consider &#39;#9e1303&#39; for second cycle of recurrence theme_cowplot() + theme(legend.position = legend_position, text = element_text(size = 17), axis.text = element_text(size = 15)) + labs(x = pc1, y = pc2) return(p) # ggplotly(p) } k_cluster_double &lt;- function(list_files1, list_files2, list_files3, cluster_n, cols, labels, legend_position, normalize, return_elbow = F) { require(factoextra) cells &lt;- c(list_files1, list_files2, list_files3) df12 &lt;- plot_pca( cells, colorBy = classes, PC1 = 1, PC2 = 2, plot = F ) df34 &lt;- plot_pca( cells, colorBy = classes, PC1 = 3, PC2 = 4, plot = F ) df56 &lt;- plot_pca( cells, colorBy = classes, PC1 = 5, PC2 = 6, plot = F ) df78 &lt;- plot_pca( cells, colorBy = classes, PC1 = 7, PC2 = 8, plot = F ) df910 &lt;- plot_pca( cells, colorBy = classes, PC1 = 9, PC2 = 10, plot = F ) df &lt;- cbind(df12, df34, df56, df78, df910) if (normalize) { # extract variance explained for each pca pca_var &lt;- as.numeric(str_match(colnames(df), &quot;\\\\(\\\\s*(.*?)\\\\s*%&quot;)[, 2]) for (i in 1:length(pca_var)) { # calculate normalized pca values norm_pca &lt;- df[, i] / 100 * pca_var[i] #repopulate the dataframe df[, i] &lt;- norm_pca } } #check best k for k-means clustering method if (return_elbow) { return(fviz_nbclust(df, kmeans, method = &quot;silhouette&quot;) + labs(subtitle = &quot;Silhouette method&quot;)) } # # # fviz_nbclust(df, kmeans, method = &quot;silhouette&quot;)+ # labs(subtitle = &quot;Silhouette method&quot;) # # fviz_nbclust(df, kmeans, nstart = 25, method = &quot;gap_stat&quot;, nboot = 50)+ # labs(subtitle = &quot;Gap statistic method&quot;) # compute k-means clustering set.seed(1) res.km &lt;- kmeans(df, cluster_n, nstart = 1000) # change colnames so it works for our plot df12$class &lt;- str_extract(rownames(df12), &#39;KRA-0\\\\d+&#39;) num &lt;- str_extract(rownames(df), &#39;_\\\\d+\\\\.&#39;) num &lt;- str_remove_all(num, pattern = &#39;\\\\.&#39;) df12$label &lt;- paste0(df12$class, num) pc1 &lt;- colnames(df12)[1] pc2 &lt;- colnames(df12)[2] colnames(df12) &lt;- c(&#39;PC1&#39;, &#39;PC2&#39;, &#39;class&#39;, &#39;label&#39;) # plot nicely p &lt;- ggplot(data = df12, aes(label = label)) + geom_point(alpha = 1.0, aes( x = PC1, y = PC2, col = as.factor(res.km$cluster) )) + theme_cowplot() + labs(x = pc1, y = pc2) + scale_color_manual(labels = labels, values = cols, name = &quot;Clone&quot;) + theme(legend.position = legend_position, text = element_text(size = 17), axis.text = element_text(size = 15)) p } } 6.7 divide_subclone_functions script: ‘extract_other_cells’, ‘extract_square’, ‘l_g’ and ‘subclone_classes_for_genomeheatmap’ functions extract_other_cells &lt;- function(kra_name, list_of_subclones) { i &lt;- which(names(man_select_files_edivisive) == kra_name) all &lt;- str_extract(man_select_files_edivisive[[i]], &#39;_\\\\d+\\\\.&#39;) %&gt;% str_remove(&#39;_&#39;) %&gt;% str_remove(&#39;\\\\.&#39;) rest &lt;- all[which(!all %in% list_of_subclones)] return(rest) } extract_square &lt;- function(list_files1, list_files2, square, x, y) { # extracts all cells that lie within a square of a pca plot defined by # user. For example square c(0.1, 0.0) will extract all cells with # pc1 lower or higher that 0.1 and pc2 lower or higher than 0.0. User has to rearange functon # if he wants x lower or higher than 0.1 cells &lt;- c(list_files1, list_files2) df12 &lt;- plot_pca(cells, colorBy = classes, PC1=1, PC2=2, plot = F) colnames(df12) &lt;- c(&#39;PC1&#39;, &#39;PC2&#39;) # extracting dataframe with correct square if(x == &#39;&lt;&#39; &amp; y == &#39;&lt;&#39;) { df12 &lt;- subset(df12, PC1 &lt; square[1] &amp; PC2 &lt; square[2]) } if(x == &#39;&lt;&#39; &amp; y == &#39;&gt;&#39;) { df12 &lt;- subset(df12, PC1 &lt; square[1] &amp; PC2 &gt; square[2]) } if(x == &#39;&gt;&#39; &amp; y == &#39;&lt;&#39;) { df12 &lt;- subset(df12, PC1 &gt; square[1] &amp; PC2 &lt; square[2]) } if(x == &#39;&gt;&#39; &amp; y == &#39;&gt;&#39;) { df12 &lt;- subset(df12, PC1 &gt; square[1] &amp; PC2 &gt; square[2]) } # numbers is: cell_id &lt;- str_extract(rownames(df12), &#39;_\\\\d+\\\\.&#39;) %&gt;% str_remove(&#39;_&#39;) %&gt;% str_remove(&#39;\\\\.&#39;) return(cell_id) } l_g &lt;- function(x, kra_num, list_cells) { select &lt;- grepl(paste0(kra_num,&#39;_&#39;,x,&quot;\\\\.&quot;), list_cells) i &lt;- which(select) return(list_cells[i]) } subclone_classes_for_genomeheatmap &lt;- function(list_of_subclones, cline) { #&#39; @param #&#39; list of subclones is the full list of rda files that have been assigned a subclone_classes_for_genomeheatmap #&#39; cline is the line (hub005, hub183 etc.) #&#39; rad is either prerad or rad #&#39; @return #&#39; returns a vector with that assigns a subclone extract_subclones &lt;- list_of_subclones[grepl(names(list_of_subclones), pattern = paste0(cline))] size_subclones &lt;- lapply(extract_subclones, length) classes &lt;- rep(names(size_subclones), size_subclones) df &lt;- data.frame(path = unlist(extract_subclones), class = classes) return(df) } 6.8 plot_genomeheatmap script: ‘genomeheatmap’ function genomeheatmap &lt;- function(selected.files, path, classes_daan = NULL, class.col = NULL, dendogram = F, daan_colours = T, name) { # This code was adapted from the AneuFinder package # plots and saves genome heatmap of selected.files # @param # selected.files: vector of location of selected files. # output path: path were plots should be saved. # name: how you want to name the plot # get platename platename &lt;- str_extract(selected.files[1], &#39;KRA-0\\\\d+&#39;) # AneuFinder functions: startTimedMessage &lt;- function(...) { x &lt;- paste0(..., collapse=&#39;&#39;) message(x, appendLF=FALSE) ptm &lt;- proc.time() return(ptm) } transCoord &lt;- function (gr) { cum.seqlengths &lt;- cumsum(as.numeric(seqlengths(gr))) cum.seqlengths.0 &lt;- c(0, cum.seqlengths[-length(cum.seqlengths)]) names(cum.seqlengths.0) &lt;- seqlevels(gr) gr$start.genome &lt;- start(gr) + cum.seqlengths.0[as.character(seqnames(gr))] gr$end.genome &lt;- end(gr) + cum.seqlengths.0[as.character(seqnames(gr))] return(gr) } stopTimedMessage &lt;- function(ptm) { time &lt;- proc.time() - ptm message(&quot; &quot;, round(time[3],2), &quot;s&quot;) } initializeStates &lt;- function (states) { somy.states &lt;- grep(&quot;somy&quot;, states, value = TRUE) somy.numbers &lt;- as.integer(sapply(strsplit(somy.states, &quot;-somy&quot;), &quot;[[&quot;, 1)) names(somy.numbers) &lt;- somy.states if (&quot;zero-inflation&quot; %in% states) { multiplicity &lt;- c(`zero-inflation` = 0, somy.numbers) } else { multiplicity &lt;- somy.numbers } levels.distributions &lt;- c(&quot;delta&quot;, &quot;dgeom&quot;, &quot;dnbinom&quot;, &quot;dbinom&quot;) distributions &lt;- rep(NA, length(states)) names(distributions) &lt;- states distributions[states == &quot;zero-inflation&quot;] &lt;- &quot;delta&quot; distributions[states == &quot;0-somy&quot;] &lt;- &quot;dgeom&quot; distributions[(states != &quot;zero-inflation&quot;) &amp; (states != &quot;0-somy&quot;)] &lt;- &quot;dnbinom&quot; states &lt;- factor(states, levels = states) distributions &lt;- factor(distributions, levels = levels.distributions) l &lt;- list(states = states, distributions = distributions, multiplicity = multiplicity) return(l) } # colours if (daan_colours) { stateColors &lt;- function(states = c(&quot;zero-inflation&quot;, paste0(0:10, &quot;-somy&quot;), &quot;total&quot;)) { state.colors &lt;- c(`zero-inflation` = &quot;#1d4661&quot;, `0-somy` = &quot;#1d4661&quot;, `1-somy` = &quot;#3787BA&quot;, `2-somy` = &quot;#95B8C5&quot;, `3-somy` = &quot;#F0ECEB&quot;, `4-somy` = &quot;#D7A290&quot;, `5-somy` = &quot;#BF583B&quot;, `6-somy` = &quot;#8D1128&quot;, `7-somy` = &quot;#3C0912&quot;, `8-somy` = &quot;black&quot;, total = &quot;black&quot;) states.with.color &lt;- intersect(states, names(state.colors)) cols &lt;- rep(&quot;black&quot;, length(states)) names(cols) &lt;- states cols[states.with.color] &lt;- state.colors[states.with.color] return(cols) } } # heatmapgenomewide adapted form AneuFinder package heatmapGenomewide_daan &lt;- function (hmms, ylabels = NULL, classes, reorder.by.class = TRUE, classes.color, file = NULL, cluster = TRUE, plot.breakpoints = FALSE, hotspots = NULL, exclude.regions = NULL) { if (!is.null(ylabels)) { if (length(ylabels) != length(hmms)) { stop(&quot;length(ylabels) must equal length(hmms)&quot;) } } if (!is.null(classes)) { if (length(classes) != length(hmms)) { stop(&quot;length(classes) must equal length(hmms)&quot;) } } if (length(classes.color) != length(unique(classes))) { stop(&quot;&#39;classes.color&#39; must have the same length as unique(classes)&quot;) } if (is.null(names(classes.color))) { names(classes.color) &lt;- unique(classes) } if (!setequal(names(classes.color), unique(classes))) { stop(&quot;The names of &#39;classes.color&#39; must be equal to the unique elements in &#39;classes&#39;&quot;) } if (length(hmms) == 1 &amp; cluster == TRUE) { cluster &lt;- FALSE warning(&quot;Cannot do clustering because only one object was given.&quot;) } hmms &lt;- loadFromFiles(hmms, check.class = c(&quot;aneuHMM&quot;, &quot;aneuBiHMM&quot;)) class.data &lt;- data.frame(ID = sapply(hmms, &quot;[[&quot;, &quot;ID&quot;)) class.data$ID &lt;- factor(class.data$ID, levels = class.data$ID) if (is.null(ylabels)) { class.data$ylabel &lt;- as.character(class.data$ID) } else { class.data$ylabel &lt;- as.character(ylabels) } class.data$class &lt;- classes mapping &lt;- class.data$ylabel names(mapping) &lt;- class.data$ID if (reorder.by.class) { cl &lt;- clusterHMMs(hmms, cluster = cluster, classes = classes, exclude.regions = exclude.regions) } else { cl &lt;- clusterHMMs(hmms, cluster = cluster, exclude.regions = exclude.regions) } hmms &lt;- hmms[cl$IDorder] class.data &lt;- class.data[cl$IDorder, ] class.data$ID &lt;- factor(class.data$ID, levels = class.data$ID) segments.list &lt;- GRangesList() for (i1 in 1:length(hmms)) { hmm &lt;- hmms[[i1]] if (is.null(hmm$segments)) { segments.list[[hmm$ID]] &lt;- GRanges() } else { segments.list[[hmm$ID]] &lt;- hmm$segments } } if (plot.breakpoints) { breakpoints &lt;- GRangesList() for (i1 in 1:length(hmms)) { hmm &lt;- hmms[[i1]] if (is.null(hmm$breakpoints)) { breakpoints[[hmm$ID]] &lt;- GRanges() } else { breakpoints[[hmm$ID]] &lt;- hmm$breakpoints } } if (length(breakpoints) == 0) { plot.breakpoints &lt;- FALSE } } ptm &lt;- startTimedMessage(&quot;Transforming coordinates ...&quot;) segments.list &lt;- endoapply(segments.list, transCoord) if (plot.breakpoints) { breakpoints &lt;- endoapply(breakpoints, transCoord) } stopTimedMessage(ptm) ptm &lt;- startTimedMessage(&quot;Making the plot ...&quot;) df &lt;- list() for (i1 in 1:length(segments.list)) { df[[length(df) + 1]] &lt;- data.frame(start = segments.list[[i1]]$start.genome, end = segments.list[[i1]]$end.genome, seqnames = seqnames(segments.list[[i1]]), ID = names(segments.list)[i1], state = segments.list[[i1]]$state) } df &lt;- do.call(rbind, df) df$ID &lt;- factor(df$ID, levels = levels(class.data$ID)) df$ylabel &lt;- mapping[as.character(df$ID)] if (plot.breakpoints) { df.breakpoints &lt;- list() for (i1 in 1:length(breakpoints)) { if (length(breakpoints[[i1]]) &gt; 0) { df.breakpoints[[length(df.breakpoints) + 1]] &lt;- data.frame(start = breakpoints[[i1]]$start.genome, end = breakpoints[[i1]]$end.genome, seqnames = seqnames(breakpoints[[i1]]), ID = names(segments.list)[i1], mid = (breakpoints[[i1]]$start.genome + breakpoints[[i1]]$end.genome)/2) } else { df.breakpoints[[length(df.breakpoints) + 1]] &lt;- data.frame(start = numeric(), end = numeric(), seqnames = character(), ID = character(), mid = numeric()) } } df.breakpoints &lt;- do.call(rbind, df.breakpoints) df.breakpoints$ID &lt;- factor(df.breakpoints$ID, levels = levels(class.data$ID)) df.breakpoints$ylabel &lt;- mapping[as.character(df.breakpoints$ID)] } cum.seqlengths &lt;- cumsum(as.numeric(seqlengths(segments.list[[1]]))) names(cum.seqlengths) &lt;- seqlevels(segments.list[[1]]) cum.seqlengths.0 &lt;- c(0, cum.seqlengths[-length(cum.seqlengths)]) names(cum.seqlengths.0) &lt;- seqlevels(segments.list[[1]]) label.pos &lt;- round(cum.seqlengths.0 + 0.5 * seqlengths(segments.list[[1]])) df.chroms &lt;- data.frame(y = c(0, cum.seqlengths), x = 1, xend = length(segments.list)) pltlist &lt;- list() widths &lt;- vector() df$state &lt;- factor(df$state, levels = names(sort(initializeStates(levels(df$state))$multiplicity))) df$x &lt;- as.numeric(df$ID) ggplt &lt;- ggplot(df) + geom_linerange(aes_string(ymin = &quot;start&quot;, ymax = &quot;end&quot;, x = &quot;x&quot;, col = &quot;state&quot;), size = 5) + scale_y_continuous(breaks = label.pos, labels = names(label.pos)) # ggplt &lt;- ggplt + scale_x_continuous(name = &quot;&quot;, # breaks = 1:length(unique(df$ylabel)), # labels = unique(df$ylabel)) ggplt &lt;- ggplt + scale_color_manual(values = stateColors(levels(df$state))) # adding custom colours # adjusintg x axis ggplt &lt;- ggplt + theme(panel.background = element_blank(), axis.ticks.x = element_blank(), axis.text.x = element_blank(), axis.line = element_blank(), axis.title.x = element_blank()) ggplt &lt;- ggplt + geom_segment(aes_string(x = &quot;x&quot;, xend = &quot;xend&quot;, y = &quot;y&quot;, yend = &quot;y&quot;), data = df.chroms, col = &quot;grey13&quot;) # adjusting y axis ggplt &lt;- ggplt + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.line = element_blank(), axis.title.x = element_blank()) # removing legend ggplt &lt;- ggplt + theme(legend.position=&quot;none&quot;) ggplt &lt;- ggplt + coord_flip() # removing all axis names ggplt &lt;- ggplt + ylab(&quot;&quot;) + xlab(&quot;&quot;) # add numeber of cells sequenced text ggplt &lt;- ggplt + annotate(&quot;text&quot;, label = paste(length(hmms), &#39;cells&#39;), x = length(hmms)/2, y = 3100000000, angle = 270, size = 50) # decreasing plot margin ggplt &lt;- ggplt + theme(plot.margin = unit(c(0,0,0,0), &quot;cm&quot;)) if (plot.breakpoints) { df.breakpoints$x &lt;- as.numeric(df.breakpoints$ID) ggplt &lt;- ggplt + geom_linerange(data = df.breakpoints, mapping = aes_string(x = &quot;x&quot;, ymin = &quot;start&quot;, ymax = &quot;end&quot;), size = 2) + ylab(&quot;&quot;) + geom_point(data = df.breakpoints, mapping = aes_string(x = &quot;x&quot;, y = &quot;mid&quot;)) } if (!is.null(hotspots)) { if (length(hotspots) &gt; 0) { df.hot &lt;- as.data.frame(transCoord(hotspots)) df.hot$xmin &lt;- 0 df.hot$xmax &lt;- length(class.data$ID) + 1 ggplt &lt;- ggplt + geom_rect(data = df.hot, mapping = aes_string(xmin = &quot;xmin&quot;, xmax = &quot;xmax&quot;, ymin = &quot;start.genome&quot;, ymax = &quot;end.genome&quot;, alpha = &quot;num.events&quot;), fill = &quot;hotpink4&quot;) + scale_alpha_continuous(name = &quot;breakpoints&quot;, range = c(0.4, 0.8)) } } width.heatmap &lt;- sum(as.numeric(seqlengths(hmms[[1]]$bins)))/3e+09 * 150 height &lt;- max(length(hmms) * 0.5, 2) pltlist[[&quot;heatmap&quot;]] &lt;- ggplt widths[&quot;heatmap&quot;] &lt;- width.heatmap # adding class colors if (!is.null(classes)) { width.classes &lt;- 5 class.data$x &lt;- as.numeric(class.data$ID) ggclass &lt;- ggplot(class.data) + geom_linerange(aes_string(ymin = 0, ymax = 1, x = &quot;x&quot;, col = &quot;class&quot;), size = 5) + guides(col = FALSE) + xlab(&quot;&quot;) ggclass &lt;- ggclass + theme(panel.background = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(), axis.line = element_blank(), axis.title.x = element_blank()) ggclass &lt;- ggclass + coord_flip() # decreasing plot margin ggclass &lt;- ggclass + theme(plot.margin = unit(c(0,0,0,0), &quot;cm&quot;)) if (!is.null(classes.color)) { ggclass &lt;- ggclass + scale_color_manual(breaks = names(classes.color), values = classes.color) } pltlist[[&quot;classbar&quot;]] &lt;- ggclass widths[&quot;classbar&quot;] &lt;- width.classes } # adding dendogram if (!is.null(cl$hclust) &amp; dendogram) { dhc &lt;- stats::as.dendrogram(cl$hclust) ddata &lt;- ggdendro::dendro_data(dhc, type = &quot;rectangle&quot;) ggdndr &lt;- ggplot(ddata$segments) + geom_segment(aes_string(x = &quot;x&quot;, xend = &quot;xend&quot;, y = &quot;y&quot;, yend = &quot;yend&quot;)) + scale_y_reverse() ggdndr &lt;- ggdndr + coord_flip() ggdndr &lt;- ggdndr + theme(panel.background = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(), axis.line = element_blank(), axis.title = element_blank()) width.dendro &lt;- 20 pltlist[[&quot;dendro&quot;]] &lt;- ggdndr widths[&quot;dendro&quot;] &lt;- width.dendro } # alligning ggpllt with dendogram and classes cowplt &lt;- cowplot::plot_grid(plotlist = rev(pltlist), align = &quot;h&quot;, ncol = length(pltlist), rel_widths = rev(widths)) stopTimedMessage(ptm) if (!is.null(file)) { ptm &lt;- startTimedMessage(&quot;Plotting to file &quot;, file, &quot; ...&quot;) ggsave(file, cowplt, width = sum(widths), height = height, units = &quot;cm&quot;, limitsize = FALSE) stopTimedMessage(ptm) } else { return(cowplt) } } #make heatmap and safe suppressWarnings(heatmapGenomewide_daan(selected.files, classes = classes_daan, classes.color = class.col, file = paste0(path, &#39;/&#39;, name, &#39;_&#39;, platename, &#39;.pdf&#39;))) return(print(paste0(name, &#39; done.&#39;))) } 6.9 fisher_test script: ‘perform_fisher’ function perform_fisher &lt;- function(dataframe, population1, population2) { #&#39; @param #&#39; dataframe is a df with columns paths and class with values &#39;hub015_rad_a&#39;, &#39;hub015_prerad_a&#39; etc. #&#39; population 1 and population two are the two pops you want to compare, for example prerad vs rad #&#39; or prerad versus rad cycle 2 #&#39; @return #&#39; returns the p value of a Fisher&#39;s exact test. If the p value is above 0.05, the distributions #&#39; pre and post rad are the same. #&#39; dataframe$rad &lt;- ifelse(dataframe$class %in% population1, &#39;pop1&#39;, ifelse(dataframe$class %in% population2, &#39;pop2&#39;, NA)) org_id &lt;- unique(str_extract(unique(dataframe$class), &#39;hub\\\\d{3}&#39;)) # remove na dataframe &lt;- dataframe[which(!is.na(dataframe$rad)),] simple_fun &lt;- function(string) { return(tail(string,1)) } dataframe$clone &lt;- unlist(lapply(stringr::str_split(dataframe$class, pattern = &#39;_&#39;), simple_fun)) # in hub015 and hub005, we defined subclones. These are actually part of the same clone, so should be # analysed together if (org_id %in% c(&#39;hub005&#39;, &#39;hub015&#39;)){ dataframe$clone &lt;- str_replace_all(dataframe$clone, pattern = &#39;a.a|a.b&#39;, replacement = &#39;a&#39;) } tab &lt;- table(dataframe$clone, dataframe$rad) # df &lt;- data.frame(cline &lt;- org_id, p_val &lt;- fisher.test(tab)$p.value) # # return(df) return(fisher.test(tab)$p.value) } 6.10 find_specific_cna_sc script: ‘find_specific_cna_sc’ function find_specific_cna_sc &lt;- function(list_resistant, list_sensitive, perc_cutoff_within_subclone_resistant, perc_cutoff_within_subclone_sensitive, per_cutoff_across_subclone_resistant, per_cutoff_across_subclone_sensitive, return_cnas_per_subclone = F) { #&#39; @param list_resistant a list subclone names which itself contains a list of paths of paths to aneuHMM .Rda files. #&#39; @param list_sensitive a list subclone names which itself contains a list of paths of paths to aneuHMM .Rda files. #&#39; @param perc_cutoff_within_subclone_resistant user defined percentage cutoff to use (e.g. 0.6 means a certain CNA is shared by 60% of the cells #&#39; within a subclone). #&#39; @param perc_cutoff_within_subclone_senstive same as in perc_cutoff_within_subclone_resistant but for the sensitive group #&#39; @param per_cutoff_across_subclone_resistant user defined percentage cutoff to use (e.g. 0.7 means a certain CNA is shared in 70% of all subclones) #&#39; @param return_cnas_per_subclone boolean. If TRUE will return the shared by perc_cutoff_within_subclone CNAs for each list of each item within #&#39; list_resistant. Note list_sensitive should be set to NULL for proper results!! #&#39; @param per_cutoff_across_subclone_sensitive same as resistant but for the sensitive group #&#39; @example perc_cutoff_within_subclone = 0.6 and per_cutoff_across_subclone = 0.7 means the algorithm will find CNAs that are shared #&#39; by 60% of single cells within each subclone, and by 70% of all subclones. Important, a cutoff of 50% is the same as computing the median. #&#39; @return a list of GRanges showing unique to list_resistant amplifications and deletions and unique to list_sensitive #&#39; amplifications and deletions or, if return_cnas_per_subclone see param return_cnas_per_subclone above. #&#39; @details Note that this algorithm is NOT sensitive to the number of single cells within each subclone. ############# # Libraries # ############# require(plyranges) require(AneuFinder) ########### # Part 1. # ########### print(&#39;Computing (this may take some minutes)...&#39;) resistant_sc &lt;- lapply(list_resistant, loadFromFiles, check.class = c(&quot;aneuHMM&quot;, &quot;aneuBiHMM&quot;)) sensitive_sc &lt;- lapply(list_sensitive, loadFromFiles, check.class = c(&quot;aneuHMM&quot;, &quot;aneuBiHMM&quot;)) # find specific CNAs needs a list of GRanges where each GRange has columns # seqnames, ranges, strand (not necessary) and cn. wrangle_sc &lt;- function(list_lff) { # segments is the reduced bins GRange (so all equal CN bins put together) wrangle_within &lt;- function(list_lff_within) { segments &lt;- list_lff_within$segments # ugly way of adding a cn column segments$cn &lt;- segments$copy.number return(segments) # END of wrange_within function } within_subcl &lt;- lapply(list_lff, wrangle_within) # END OF wrangle_sc function } list_resistant &lt;- lapply(resistant_sc, wrangle_sc) list_sensitive &lt;- lapply(sensitive_sc, wrangle_sc) print(&#39;Extracted segment info from files&#39;) Sys.sleep(1) ########### # Part 2. # ########### # The Granges are now still arranged in bins. We are first going to # combine bins with similar copy number. print(&#39;Computing (this may take some minutes)...&#39;) combine_indels &lt;- function(subclone_consensus) { #&#39; @param subclone_consensus_list is a GRanges with seqnames, ranges, strand and cn #&#39; @returns list of Granges where each Granges has only CNA of cn2 or cn&gt;2 combine_within &lt;- function(subclone_consensus_within) { # subset subclone_consensus in cn &lt;2, cn = 2 and cn &gt; 2 cn_less_2 &lt;- subclone_consensus_within[subclone_consensus_within$cn &lt; 2,] cn_more_2 &lt;- subclone_consensus_within[subclone_consensus_within$cn &gt; 2,] # reduce each GRanges (joins consecutive ranges together) cn_less_2 &lt;- reduce(cn_less_2) cn_more_2 &lt;- reduce(cn_more_2) # reduce deletes metadata. # adding metadata cn_less_2$cn &lt;- rep(&#39;&lt;2&#39;, length(cn_less_2)) cn_more_2$cn &lt;- rep(&#39;&lt;2&#39;, length(cn_more_2)) # make list and rename items GR_list &lt;- GRangesList(cn_less_2, cn_more_2) names(GR_list) &lt;- c(&#39;&lt;2&#39;, &#39;&gt;2&#39;) # Return # return(GR_list) } combine_subcl &lt;- lapply(subclone_consensus, combine_within) } # run an apply function here on each Granges in list_resistant versus list_sensitive resistant_split &lt;- lapply(list_resistant, combine_indels) sensitive_split &lt;- lapply(list_sensitive, combine_indels) # splits deletions together within each subclone grouper_del &lt;- function(gr) { grouper_within &lt;- function(gr_within) { return(gr_within$&#39;&lt;2&#39;) } within_grouper &lt;- lapply(gr, grouper_within) } # splits amplifciations together within each subclone grouper_ampl &lt;- function(gr) { grouper_within &lt;- function(gr_within) { return(gr_within$&#39;&gt;2&#39;) } within_grouper &lt;- lapply(gr, grouper_within) } # run apply on each subclone resistant_split_del &lt;- lapply(resistant_split, grouper_del) resistant_split_ampl &lt;- lapply(resistant_split, grouper_ampl) sensitive_split_del &lt;- lapply(sensitive_split, grouper_del) sensitive_split_ampl &lt;- lapply(sensitive_split, grouper_ampl) ########### # Part 3. # ########### # Part 3A # ########### # Finding common CNAs within each subclone shared_cnas &lt;- function(list_GRanges, perc_cutoff_within_subclone) { #&#39; @param list_GRanges is a list of GRanges with seqnames, ranges, strand and cn #&#39; @param perc_cutoff_within_subclone user defined percentage cutoff to use (e.g. 0.6) #&#39; @returns Granges where each Granges is shared by =&gt; perc_cutoff_within_subclone # finding overlaps in x% of regions: wait for response community: # https://stackoverflow.com/questions/74900085/find-ranges-that-are-shared-by-80-or-more-of-10-granges-objects # https://support.bioconductor.org/p/9148540/ shared_cnas_within &lt;- function(list_GRanges_within) { n &lt;- length(list_GRanges_within) # number of range sets shared_cna &lt;- bind_ranges(list_GRanges_within, .id = &quot;origin&quot;) %&gt;% compute_coverage() %&gt;% mutate(fraction_cov = score / n) %&gt;% filter(fraction_cov &gt;= perc_cutoff_within_subclone) %&gt;% reduce_ranges() return(shared_cna) } lapply(list_GRanges, shared_cnas_within) } resistant_shared_del &lt;- shared_cnas(resistant_split_del, perc_cutoff_within_subclone = perc_cutoff_within_subclone_resistant) resistant_shared_ampl &lt;- shared_cnas(resistant_split_ampl, perc_cutoff_within_subclone = perc_cutoff_within_subclone_resistant) sensitive_shared_del &lt;- shared_cnas(sensitive_split_del, perc_cutoff_within_subclone = perc_cutoff_within_subclone_sensitive) sensitive_shared_ampl &lt;- shared_cnas(sensitive_split_ampl, perc_cutoff_within_subclone = perc_cutoff_within_subclone_sensitive) # END of function if return_cnas_per_subclone == T if (return_cnas_per_subclone == T) { cna_list &lt;- list (deletions = c(resistant_shared_del, sensitive_shared_del), amplifications = c(resistant_shared_ampl, sensitive_shared_del)) print( paste0( &#39;Extracted CNAs that are shared by &#39;, as.numeric(perc_cutoff_within_subclone_resistant) * 100, &#39;% of single cells within each resistant subclone, and by &#39;, as.numeric(perc_cutoff_within_subclone_sensitive) * 100, &#39;% of single cells within each sensitive subclone&#39; ) ) ########## # Unload # ########## suppressWarnings(invisible(lapply(paste0(&quot;package:&quot;, names(sessionInfo()$otherPkgs)), # Unload add-on packages detach, character.only = TRUE, unload = TRUE))) return(cna_list) } # Part 3B # ########### # Finding common CNAs across subclones shared_cnas_across_subclones &lt;- function(list_GRanges, per_cutoff_across_subclone) { #&#39; @param list_GRanges is a list of GRanges with seqnames, ranges, strand and cn #&#39; @param perc_cutoff user defined percentage cutoff to use (e.g. 0.6) #&#39; @returns Granges where each Granges is shared by =&gt; perc_cutoff_within_subclone # finding overlaps in x% of regions: wait for response community: # https://stackoverflow.com/questions/74900085/find-ranges-that-are-shared-by-80-or-more-of-10-granges-objects # https://support.bioconductor.org/p/9148540/ n &lt;- length(list_GRanges) # number of range sets shared_cna &lt;- bind_ranges(list_GRanges, .id = &quot;origin&quot;) %&gt;% compute_coverage() %&gt;% mutate(fraction_cov = score / n) %&gt;% filter(fraction_cov &gt;= per_cutoff_across_subclone) %&gt;% reduce_ranges() return(shared_cna) } resistant_shared_del_across &lt;- shared_cnas_across_subclones(resistant_shared_del, per_cutoff_across_subclone = per_cutoff_across_subclone_resistant) resistant_shared_ampl_across &lt;- shared_cnas_across_subclones(resistant_shared_ampl, per_cutoff_across_subclone = per_cutoff_across_subclone_resistant) sensitive_shared_del_across &lt;- shared_cnas_across_subclones(sensitive_shared_del, per_cutoff_across_subclone = per_cutoff_across_subclone_sensitive) sensitive_shared_ampl_across &lt;- shared_cnas_across_subclones(sensitive_shared_ampl, per_cutoff_across_subclone = per_cutoff_across_subclone_sensitive) print( paste0( &#39;Extracted CNAs that are shared by &#39;, as.numeric(perc_cutoff_within_subclone_resistant) * 100, &#39; and &#39;, as.numeric(perc_cutoff_within_subclone_sensitive) * 100, &#39;% of single cells within resistant and sensitive subclones, respectively, and that are shared by &#39;, as.numeric(per_cutoff_across_subclone_resistant) * 100, &#39; and &#39;, as.numeric(per_cutoff_across_subclone_sensitive) * 100, &#39;% across resistant and sensitive subclones, respectively.&#39; ) ) Sys.sleep(1) print(&#39;Computing (few seconds)...&#39;) Sys.sleep(2) ########### # Part 4. # ########### # Now that we have shared CNAs across subclones with the resistant and sensitive group, we need to extract # only those CNAs that are unique to the resistant group. # unique to resistant lines deletions: unique_resistant_del &lt;- setdiff(resistant_shared_del_across, sensitive_shared_del_across) # unique to resistant lines amplifications unique_resistant_ampl &lt;- setdiff(resistant_shared_ampl_across, sensitive_shared_ampl_across) # unique to sensitive lines deletions: unique_sensitive_del &lt;- setdiff(sensitive_shared_del_across, resistant_shared_del_across) # unique to sensitive lines amplifications: unique_sensitive_ampl &lt;- setdiff(sensitive_shared_ampl_across, resistant_shared_ampl_across) print( &#39;Identified amplifications and deletions that are unique to resistant or sensitive subclones&#39; ) ########## # Return # ########## returner &lt;- list( unique_resistant_del, unique_resistant_ampl, unique_sensitive_del, unique_sensitive_ampl ) names(returner) &lt;- c( &#39;unique_resistant_del&#39;, &#39;unique_resistant_ampl&#39;, &#39;unique_sensitive_del&#39;, &#39;unique_sensitive_ampl&#39; ) ########## # Unload # ########## suppressWarnings(invisible(lapply(paste0(&quot;package:&quot;, names(sessionInfo()$otherPkgs)), # Unload add-on packages detach, character.only = TRUE, unload = TRUE))) return(returner) } 6.11 get_cytoband_coverage script: ‘get_cytoband_coverage’ function get_cytoband_coverage &lt;- function(Grange) { #&#39; @param Grange a grange with seqnames and granges. #&#39; @returns returns a GRange with cytogenetic locations including #&#39; percentage of overlap and a dataframe containing information on how much of #&#39; the total arm was affected. ############# # Libraries # ############# require(tidyverse) require(plyranges) ######## # Data # ######## # Uncomment me, this is to download cytogenetic coordinates # library(biovizBase) # hg38IdeogramCyto &lt;- getIdeogram(&quot;hg38&quot;, cytobands = TRUE) # save(hg38IdeogramCyto, file = &#39;rda/cna_analysis/hg38IdeogramCyto.rda&#39;) # !!! ADDING ../cna_analysis for publication in GitHub !!! load(&#39;../cna_analysis/rda/cna_analysis/hg38IdeogramCyto.rda&#39;) ########### # Wrangle # ########### # Convert both GRanges to similar karyogram style seqlevelsStyle(Grange) &lt;- &quot;NCBI&quot; seqlevelsStyle(hg38IdeogramCyto) &lt;- &quot;NCBI&quot; Grange_list_cytoband &lt;- list() Grange_list_pq_affected &lt;- list() # return empty Grange and empty data.frame if Grange is empty if (length(Grange) == 0) { # return empty Grange return(list(GRanges( seqnames = character(0), IRanges(start = integer(0), end = integer(0)), cytobands_cov = character(0) ), data.frame(seqnames = character(), start_of_arm = numeric(), end_of_arm = numeric(), width_of_arm = numeric(), strand = character(), chromosome = character(), arm = character(), percentage_arm_affected = numeric(), stringsAsFactors = FALSE) )) } for (row in 1:length(Grange)) { for_range &lt;- Grange[row] ########## # Part 1 # ########## ## First find specific cytoband locations # finding overlaps hits &lt;- findOverlaps(for_range, hg38IdeogramCyto) # computing percentage overlap overlaps &lt;- pintersect(for_range[queryHits(hits)], hg38IdeogramCyto[subjectHits(hits)]) percentOverlap &lt;- width(overlaps) / width(hg38IdeogramCyto[subjectHits(hits)]) # extracting cytobands cytobands &lt;- paste0(seqnames(hg38IdeogramCyto[subjectHits(hits)]), hg38IdeogramCyto[subjectHits(hits)]$name) # replace &#39;chr&#39; cytobands &lt;- str_replace(cytobands, pattern = &#39;chr&#39;, replacement = &#39;&#39;) cytobands_cov &lt;- list(paste0(cytobands, &#39;;&#39;, round(percentOverlap, 2) * 100, &#39;%&#39;)) for_range$cytobands_cov &lt;- cytobands_cov Grange_list_cytoband[[row]] &lt;- for_range ########## # Part 2 # ########## # make dataframe that shows how much of an arm is affected # Grange with p and q IRanges p_q &lt;- hg38IdeogramCyto p_q$arm &lt;- str_extract(p_q$name, &#39;p|q&#39;) p_q &lt;- subset(p_q, seqnames %in% c(seq(1:22), &#39;X&#39;, &#39;Y&#39;)) p_q &lt;- p_q %&gt;% group_by(seqnames, arm) %&gt;% reduce_ranges() # finding overlaps hits_pq &lt;- findOverlaps(for_range, p_q) # computing percentage overlap overlaps &lt;- pintersect(for_range[queryHits(hits_pq)], p_q[subjectHits(hits_pq)]) percentOverlap &lt;- width(overlaps) / width(p_q[subjectHits(hits_pq)]) p_q_percentage &lt;- as.data.frame(p_q[subjectHits(hits_pq)]) p_q_percentage$percentage_arm_affected &lt;- percentOverlap * 100 colnames(p_q_percentage) &lt;- c( &#39;seqnames&#39;, &#39;start_of_arm&#39;, &#39;end_of_arm&#39;, &#39;width_of_arm&#39;, &#39;strand&#39;, &#39;chromosome&#39;, &#39;arm&#39;, &#39;percentage_arm_affected&#39; ) Grange_list_pq_affected[[row]] &lt;- p_q_percentage } Grange &lt;- bind_ranges(Grange_list_cytoband) pq_arm_affect &lt;- bind_rows(Grange_list_pq_affected) return(list(Grange, pq_arm_affect)) ### END of function ### } 6.12 get_genes script: ‘get_genes’ functoin get_genes &lt;- function(GRange) { #&#39; @param Grange a grange with seqnames and granges. #&#39; @returns returns df with all genes encoded within the GRange regions. require(GenomicRanges) require(biomaRt) # This code should be run only once and is therefore commented. # code from: https://www.biostars.org/p/311199/ # Set up an gene annotation template to use # mart &lt;- useMart(biomart=&quot;ensembl&quot;, dataset=&quot;hsapiens_gene_ensembl&quot;) # mart &lt;- useMart(biomart=&quot;ENSEMBL_MART_ENSEMBL&quot;, host=&quot;www.ensembl.org&quot;, path=&quot;/biomart/martservice&quot;, dataset=&quot;hsapiens_gene_ensembl&quot;) # genes &lt;- getBM(attributes=c(&quot;hgnc_symbol&quot;,&quot;chromosome_name&quot;,&quot;start_position&quot;,&quot;end_position&quot;), mart=mart) # genes &lt;- genes[genes[,1]!=&quot;&quot; &amp; genes[,2] %in% c(1:22,&quot;X&quot;,&quot;Y&quot;),] # xidx &lt;- which(genes[,2]==&quot;X&quot;) # yidx &lt;- which(genes[,2]==&quot;Y&quot;) # genes[xidx, 2] &lt;- 23 # genes[yidx, 2] &lt;- 24 # genes[,2] &lt;- sapply(genes[,2],as.integer) # genes &lt;- genes[order(genes[,3]),] # genes &lt;- genes[order(genes[,2]),] # save(genes, file = &#39;rda/cna_analysis/genes.rda&#39;) # colnames(genes) &lt;- c(&quot;GeneSymbol&quot;,&quot;Chr&quot;,&quot;Start&quot;,&quot;End&quot;) # genes_GR &lt;- makeGRangesFromDataFrame(genes,keep.extra.columns = TRUE) # save(genes_GR, file = &#39;rda/cna_analysis/genes_GR.rda&#39;) # loading genelist and genomic location load(&quot;../cna_analysis/rda/cna_analysis/genes_GR.rda&quot;, envir = .GlobalEnv) load(&#39;../cna_analysis/rda/cna_analysis/genes.rda&#39;, envir = .GlobalEnv ) # Convert both GRanges to similar karyogram style seqlevelsStyle(GRange) &lt;- &quot;UCSC&quot; GRange &lt;- renameSeqlevels(GRange, paste0(&#39;chr&#39;, c(1:23))) seqlevelsStyle(genes_GR) &lt;- &quot;UCSC&quot; # Finding hits with genes_GR and GRanges hits &lt;- findOverlaps(genes_GR, GRange, type=&quot;within&quot;) # constructing df &lt;- cbind(as.data.frame(GRange)[subjectHits(hits),],genes[queryHits(hits),]) return(df) } 6.13 get_oncogenes scripts: ‘get_oncogenes’ function get_oncogenes &lt;- function(GRange) { #&#39; @param Grange a grange with seqnames and granges. #&#39; @returns returns df with all genes encoded within the GRange regions. source(&#39;R/get_genes.R&#39;) # first finding all genes within GRange all_genes &lt;- get_genes(GRange) # change colnames so dataframes match colnames(all_genes)[which(names(all_genes) == &#39;hgnc_symbol&#39;)] &lt;- &quot;Gene Symbol&quot; # downloading oncogenes require(readr) oncogenes &lt;- read_csv(&quot;../cna_analysis/data/cna_analysis/Census_allMon May 30 12_43_01 2022.csv&quot;) # subset df_genes so to only have oncogenes require(tidyverse) oncogenes &lt;- inner_join(oncogenes, all_genes) return(oncogenes) } 6.14 plot_genes_karyotype script: ‘plot_genes_karyotype’ function plot_genes_karyotype &lt;- function(GRange, dist = -30, show_genes, show_chromosomes = c( &quot;chr1&quot;, &quot;chr2&quot;, &quot;chr3&quot;, &quot;chr4&quot;, &quot;chr5&quot;, &quot;chr6&quot;, &quot;chr7&quot;, &quot;chr8&quot;, &quot;chr9&quot;, &quot;chr10&quot;, &quot;chr11&quot;, &quot;chr12&quot;, &quot;chr13&quot;, &quot;chr14&quot;, &quot;chr15&quot;, &quot;chr16&quot;, &quot;chr17&quot;, &quot;chr18&quot;, &quot;chr19&quot;, &quot;chr20&quot;, &quot;chr21&quot;, &quot;chr22&quot;, &quot;chrX&quot; )) { #&#39; @param GRange a GRange with seqnames, ranges, strand and hgnc_symbol #&#39; @param dist How far away the genes should be plotted from the lines. #&#39; Between -40 and -70 seems to do the trick most of the times. #&#39; @param show_genes is a vector of gene symbols to show. #&#39; @param show_chromosomes is a vector indicating which chromosomes to show. #&#39; @return a karyotype with genes labeled #&#39; @details. Throws an error when the GRange does not contain either #&#39; ampflications or deletions. This can be ignored, the resulting plot #&#39; is correct ############# # Libraries # ############# require(karyoploteR) require(stringr) ########### # Wrangle # ########### # making sure seqlevels match seqlevelsStyle(GRange) &lt;- &#39;UCSC&#39; kp &lt;- plotKaryotype( &quot;hg38&quot;, plot.type = 5, labels.plotter = NULL, main = &quot;&quot;, cex = 4, chromosomes = show_chromosomes ) #renaming seqlevels seqlevels_grange_change &lt;- str_replace_all(seqlevels(GRange), pattern = &#39;chr23&#39;, replacement = &#39;chrX&#39;) GRange &lt;- renameSeqlevels(GRange, value = seqlevels_grange_change) kpAddChromosomeNames( kp, chr.names = str_remove_all(show_chromosomes, &#39;chr&#39;), cex = 1.3 ) # split into amplifications and deletions ampl &lt;- GRange[GRange$cn == &#39;amplified&#39;] ampl &lt;- ampl[ampl$hgnc_symbol %in% show_genes] del &lt;- GRange[GRange$cn == &#39;deleted&#39;] del &lt;- del[del$hgnc_symbol %in% show_genes] tryCatch( cor &lt;- cor.test(df$AUC, df$dependency, use = &quot;complete.obs&quot;), error = function(e) NULL ) tryCatch( kpPlotMarkers( kp, data = ampl, labels = ampl$hgnc_symbol, ignore.chromosome.ends = T, r0 = 1, r1 = 0.85, label.dist = 0.003, label.margin = dist, marker.parts = c(0.3, 0.1, 0.1), line.color = &#39;firebrick&#39;, label.color = &#39;firebrick&#39; ), error = function(e) NULL ) tryCatch( kpPlotMarkers( kp, data = del, labels = del$hgnc_symbol, ignore.chromosome.ends = T, r0 = 1, r1 = 0.4, label.dist = 0.003, cex = 8, label.margin = dist, marker.parts = c(0.3, 0.1, 0.1), line.color = &#39;steelblue&#39;, label.color = &#39;steelblue&#39; ), error = function(e) NULL ) } 6.15 shifters script: ‘create_cn_matrix’ and ‘cluster_and_shift_transitions’ functions For the ‘create_cn_matrix’ and ‘cluster_and_shift_transitions’ functions, please submit a code sharing request to the corresponding author of this paper: Bolhaqueiro, A.C.F., Ponsioen, B., Bakker, B. et al. Ongoing chromosomal instability and karyotype evolution in human colorectal cancer organoids. Nat Genet 51, 824–834 (2019). https://doi-org.proxy.library.uu.nl/10.1038/s41588-019-0399-6 6.16 calculate_heterogeneity_score script: ‘calculate_heterogeneity_score’ function For the ‘calculate_heterogeneity_score’ function, please submit a code sharing request to the corresponding author of this paper: Bolhaqueiro, A.C.F., Ponsioen, B., Bakker, B. et al. Ongoing chromosomal instability and karyotype evolution in human colorectal cancer organoids. Nat Genet 51, 824–834 (2019). https://doi-org.proxy.library.uu.nl/10.1038/s41588-019-0399-6 6.17 cna_profiler script: ‘cna_profiler’ function cna_profiler &lt;- function(df) { #&#39; @param df is a datafame containing all the copy number calls of all the files. #&#39; Columns: 01) seqnames #&#39; 02) start #&#39; 03) end #&#39; 04) width #&#39; 05) strand #&#39; 06) [copy.number cell 1] #&#39; 07) [copy.number cell 2], etc. #&#39; @return Outputs a dataframe that states the ratio (normalized to total cells) of #&#39; small, medium, large and whole chromosome CNAs require(tidyverse) require(GWASTools) # defining some parameters # number of cells n_cells &lt;- ncol(df) - 5 # extract centromere positions data(centromeres.hg38) centromeres.hg38 &lt;- subset(centromeres.hg38, chrom != &#39;Y&#39;) names(centromeres.hg38) &lt;- c(&#39;seqnames&#39;, &#39;start&#39;, &#39;end&#39;) # extract total length chromosomes total_length &lt;- df %&gt;% group_by(seqnames) %&gt;% summarize(sum(width)) # construct dataframe containing chromosome name, centromere position (start and end) and total length chromosome chrom_centro_total &lt;- inner_join(total_length, centromeres.hg38) # compute arm lengths chrom_centro_total$p_arm &lt;- chrom_centro_total$start + (chrom_centro_total$end-chrom_centro_total$start) chrom_centro_total$q_arm &lt;- chrom_centro_total$`sum(width)` - chrom_centro_total$p_arm ##### !!!!!!!! ###### # Check if this is still correct when using new assemblies ! # now all p_arms except for chromosome 1 are correct (for some reason the p-arm is the larger arm here). # I am going to swithc it. p_arm_1 &lt;- chrom_centro_total$q_arm[1] q_arm_1 &lt;- chrom_centro_total$p_arm[1] chrom_centro_total[1,5] &lt;- p_arm_1 chrom_centro_total[1,6] &lt;- q_arm_1 # function to extract CNA for each chromosome, run this function for each chromosome cna_extract &lt;- function(chromosome) { # @parama: chromosome is the chromosome (i.e., 1, 2,3, X, etc) df_chrom &lt;- subset(df, seqnames == chromosome) # run this function for each column in df_chrom cna_extract_cell &lt;- function(column_i) { # @ param column i is the integer of the column in df_chrom # from which to extract CNAs # extract rows that switch CNA value (for example from 2 to 3) CNA_change &lt;- which(c(FALSE, tail(df_chrom[,column_i],-1) != head(df_chrom[,column_i],-1))) # extract indices CNA_change_indices &lt;- unique(sort(c(1,CNA_change, (CNA_change-1), nrow(df_chrom)))) # construct dataframe containing end and start of each CNA CNA_change_df &lt;- df_chrom[CNA_change_indices,c(1,2,3,4,5, column_i)] names(CNA_change_df) &lt;- c(&#39;seqnames&#39;, &#39;start&#39;, &#39;end&#39;, &#39;width&#39;, &#39;strand&#39;, &#39;cna&#39;) start_list &lt;- list() end_list &lt;- list() i &lt;- 1 while(i&lt;=nrow(CNA_change_df)){ try(if(CNA_change_df[i+1, 6] == CNA_change_df[i, 6]){ start_list[[(length(start_list) + 1)]] &lt;- CNA_change_df[i,2] end_list[[(length(end_list) + 1)]] &lt;- CNA_change_df[i+1, 3] i &lt;- i+2 }) if(CNA_change_df[i+1, 6] != CNA_change_df[i, 6] || is.na(CNA_change_df[i+1, 6])){ start_list[[(length(start_list) + 1)]] &lt;- CNA_change_df[i,2] end_list[[(length(end_list) + 1)]] &lt;- CNA_change_df[i, 3] i &lt;- i+1 } } # constructing a dataframe cna_dataframe &lt;- data.frame(seqnames = chromosome, start = unlist(start_list), end = unlist(end_list)) # remove NA cna_dataframe &lt;- na.omit(cna_dataframe) # add column CNA cna_dataframe$cna &lt;- (CNA_change_df %&gt;% filter(cna!=lag(cna) | is.na(lag(cna))))$cna # remove columsn with cna == 2 (this is no CNA but normal diploid) cna_dataframe &lt;- subset(cna_dataframe, cna != 2) # add total number of CNAs in this cell as colunn num_cna try(cna_dataframe$num_cna &lt;- length(cna_dataframe$cna), silent = T) # add a width column of the CNA cna_dataframe$width &lt;- cna_dataframe$end - cna_dataframe$start + 1 # extract chromosome specifics chrom_df &lt;- subset(chrom_centro_total, seqnames == chromosome) # in the next of code, we are going to compute the fraction of SCNA # Important: using this measure, a fraction of 1 means that a region the size of one arm # was affected. A fraction of 2 means the whole chromosome is affected. Note that these CNA # can cross centromeres, so we are unable to easily assign if it is the p-arm or q-arm that is # affected. cna_dataframe$fraction &lt;- ifelse(cna_dataframe$end &lt; chrom_df$p_arm, (cna_dataframe$width / chrom_df$p_arm), ifelse(cna_dataframe$start &gt; chrom_df$p_arm, cna_dataframe$width / chrom_df$q_arm, (((chrom_df$p_arm - cna_dataframe$start) / chrom_df$p_arm) + ((cna_dataframe$end - chrom_df$p_arm) / chrom_df$q_arm)))) # adding cellname try(cna_dataframe$cell_id &lt;- colnames(df_chrom)[column_i], silent = T) return(cna_dataframe) } # running for each cell. cna_list &lt;- lapply(6:ncol(df), cna_extract_cell) # constructing single dataframe cna_df &lt;- bind_rows(cna_list, .id = &quot;cell_num_scar&quot;) # removing cell_num scar cna_df &lt;- cna_df[, 2:ncol(cna_df)] return(cna_df) } cna_df_per_chrom_list &lt;- list() for(chrom in unique(df$seqnames)) { cna_df_per_chrom_list[[chrom]] &lt;- cna_extract(chrom) } # constructing single dataframe cna_df_per_chrom_df &lt;- bind_rows(cna_df_per_chrom_list, .id = &quot;chrom_scar&quot;) # removing cell_num scar cna_df_per_chrom_df &lt;- cna_df_per_chrom_df[, 2:ncol(cna_df_per_chrom_df)] } 6.18 cin_signature_ccle script: ‘run_cin_ccle’ function run_cin_ccle &lt;- function(cnv, d) { #&#39; @param cnv is segmental data to input in CINSignatureQuantification #&#39; @param d is a dataframe with sample metadata that is joined with cnv #&#39; @return outputs CIN signature values. ############# # Libraries # ############# require(CINSignatureQuantification) require(tidyverse) ########### # Wrangle # ########### wrangler_cin_signature_ccle &lt;- function(df) { #&#39; @param df: A dataframe containing all the copy number calls of all the files. #&#39; @return a dataframe in the format https://github.com/markowetzlab/CINSignatureQuantification # remove unwanted column names keep_columns &lt;- c(&#39;Chromosome&#39;, &#39;Start&#39;, &#39;End&#39;, &#39;Segment_Mean&#39;, &#39;DepMap_ID&#39;) new_df &lt;- subset(df, select = keep_columns) # reorder columns col_order &lt;- c(&#39;Chromosome&#39;, &#39;Start&#39;, &#39;End&#39;, &#39;Segment_Mean&#39;, &#39;DepMap_ID&#39;) new_df &lt;- new_df[, col_order] # define new column names column_names &lt;- c(&#39;chromosome&#39;, &#39;start&#39;, &#39;end&#39;, &#39;segVal&#39;, &#39;sample&#39;) colnames(new_df) &lt;- column_names return(new_df) } # Subset cnv to only include samples where radiation sensitivity is known cnv &lt;- cnv[cnv$DepMap_ID %in% d$DepMap_ID,] # Wrangle cnv &lt;- wrangler_cin_signature_ccle(cnv) # The CIN algorithm (run with quantifyCNSignatures) does not support Y chromosome, we have to get rid of those. cnv &lt;- cnv[cnv$chromosome != &#39;Y&#39;, ] ####### # Run # ####### # Running the CIN scores cin_scores &lt;- quantifyCNSignatures(cnv, build = &#39;hg38&#39;) # Extracting the values. cin_values &lt;- getActivities(cin_scores) ########### # Wrangle # ########### cin_df &lt;- as.data.frame(cin_values) cin_df$DepMap_ID &lt;- rownames(cin_df) cin_df &lt;- gather(cin_df, cx_signature, cx_value, CX1:CX17, factor_key = T) # add some metadata cin_df &lt;- inner_join(cin_df, d) ########## # Return # ########## return(cin_df) } "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
